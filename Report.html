<!DOCTYPE html>
<!-- saved from url=(0077)file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html -->
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">


<meta name="generator" content="quarto-1.2.335">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Nealson Setiawan">

<title>Sentimental Analysis on Amazon Reviews</title>
<style class="anchorjs"></style><style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="./Report_files/clipboard.min.js.download"></script>
<script src="./Report_files/quarto.js.download"></script>
<script src="./Report_files/popper.min.js.download"></script>
<script src="./Report_files/tippy.umd.min.js.download"></script>
<script src="./Report_files/anchor.min.js.download"></script>
<link href="./Report_files/tippy.css" rel="stylesheet">
<link href="./Report_files/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="./Report_files/bootstrap.min.js.download"></script>
<link href="./Report_files/bootstrap-icons.css" rel="stylesheet">
<link href="./Report_files/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script src="./Report_files/require.min.js.download" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="./Report_files/jquery.min.js.download" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="./Report_files/tex-chtml-full.js.download" type="text/javascript"></script><style type="text/css">.CtxtMenu_InfoClose {  top:.2em; right:.2em;}
.CtxtMenu_InfoContent {  overflow:auto; text-align:left; font-size:80%;  padding:.4em .6em; border:1px inset; margin:1em 0px;  max-height:20em; max-width:30em; background-color:#EEEEEE;  white-space:normal;}
.CtxtMenu_Info.CtxtMenu_MousePost {outline:none;}
.CtxtMenu_Info {  position:fixed; left:50%; width:auto; text-align:center;  border:3px outset; padding:1em 2em; background-color:#DDDDDD;  color:black;  cursor:default; font-family:message-box; font-size:120%;  font-style:normal; text-indent:0; text-transform:none;  line-height:normal; letter-spacing:normal; word-spacing:normal;  word-wrap:normal; white-space:nowrap; float:none; z-index:201;  border-radius: 15px;                     /* Opera 10.5 and IE9 */  -webkit-border-radius:15px;               /* Safari and Chrome */  -moz-border-radius:15px;                  /* Firefox */  -khtml-border-radius:15px;                /* Konqueror */  box-shadow:0px 10px 20px #808080;         /* Opera 10.5 and IE9 */  -webkit-box-shadow:0px 10px 20px #808080; /* Safari 3 & Chrome */  -moz-box-shadow:0px 10px 20px #808080;    /* Forefox 3.5 */  -khtml-box-shadow:0px 10px 20px #808080;  /* Konqueror */  filter:progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color="gray", Positive="true"); /* IE */}
</style><style type="text/css">.CtxtMenu_MenuClose {  position:absolute;  cursor:pointer;  display:inline-block;  border:2px solid #AAA;  border-radius:18px;  -webkit-border-radius: 18px;             /* Safari and Chrome */  -moz-border-radius: 18px;                /* Firefox */  -khtml-border-radius: 18px;              /* Konqueror */  font-family: "Courier New", Courier;  font-size:24px;  color:#F0F0F0}
.CtxtMenu_MenuClose span {  display:block; background-color:#AAA; border:1.5px solid;  border-radius:18px;  -webkit-border-radius: 18px;             /* Safari and Chrome */  -moz-border-radius: 18px;                /* Firefox */  -khtml-border-radius: 18px;              /* Konqueror */  line-height:0;  padding:8px 0 6px     /* may need to be browser-specific */}
.CtxtMenu_MenuClose:hover {  color:white!important;  border:2px solid #CCC!important}
.CtxtMenu_MenuClose:hover span {  background-color:#CCC!important}
.CtxtMenu_MenuClose:hover:focus {  outline:none}
</style><style type="text/css">.CtxtMenu_Menu {  position:absolute;  background-color:white;  color:black;  width:auto; padding:5px 0px;  border:1px solid #CCCCCC; margin:0; cursor:default;  font: menu; text-align:left; text-indent:0; text-transform:none;  line-height:normal; letter-spacing:normal; word-spacing:normal;  word-wrap:normal; white-space:nowrap; float:none; z-index:201;  border-radius: 5px;                     /* Opera 10.5 and IE9 */  -webkit-border-radius: 5px;             /* Safari and Chrome */  -moz-border-radius: 5px;                /* Firefox */  -khtml-border-radius: 5px;              /* Konqueror */  box-shadow:0px 10px 20px #808080;         /* Opera 10.5 and IE9 */  -webkit-box-shadow:0px 10px 20px #808080; /* Safari 3 & Chrome */  -moz-box-shadow:0px 10px 20px #808080;    /* Forefox 3.5 */  -khtml-box-shadow:0px 10px 20px #808080;  /* Konqueror */}
.CtxtMenu_MenuItem {  padding: 1px 2em;  background:transparent;}
.CtxtMenu_MenuArrow {  position:absolute; right:.5em; padding-top:.25em; color:#666666;  font-family: null; font-size: .75em}
.CtxtMenu_MenuActive .CtxtMenu_MenuArrow {color:white}
.CtxtMenu_MenuArrow.CtxtMenu_RTL {left:.5em; right:auto}
.CtxtMenu_MenuCheck {  position:absolute; left:.7em;  font-family: null}
.CtxtMenu_MenuCheck.CtxtMenu_RTL { right:.7em; left:auto }
.CtxtMenu_MenuRadioCheck {  position:absolute; left: .7em;}
.CtxtMenu_MenuRadioCheck.CtxtMenu_RTL {  right: .7em; left:auto}
.CtxtMenu_MenuInputBox {  padding-left: 1em; right:.5em; color:#666666;  font-family: null;}
.CtxtMenu_MenuInputBox.CtxtMenu_RTL {  left: .1em;}
.CtxtMenu_MenuComboBox {  left:.1em; padding-bottom:.5em;}
.CtxtMenu_MenuSlider {  left: .1em;}
.CtxtMenu_SliderValue {  position:absolute; right:.1em; padding-top:.25em; color:#333333;  font-size: .75em}
.CtxtMenu_SliderBar {  outline: none; background: #d3d3d3}
.CtxtMenu_MenuLabel {  padding: 1px 2em 3px 1.33em;  font-style:italic}
.CtxtMenu_MenuRule {  border-top: 1px solid #DDDDDD;  margin: 4px 3px;}
.CtxtMenu_MenuDisabled {  color:GrayText}
.CtxtMenu_MenuActive {  background-color: #606872;  color: white;}
.CtxtMenu_MenuDisabled:focus {  background-color: #E8E8E8}
.CtxtMenu_MenuLabel:focus {  background-color: #E8E8E8}
.CtxtMenu_ContextMenu:focus {  outline:none}
.CtxtMenu_ContextMenu .CtxtMenu_MenuItem:focus {  outline:none}
.CtxtMenu_SelectionMenu {  position:relative; float:left;  border-bottom: none; -webkit-box-shadow:none; -webkit-border-radius:0px; }
.CtxtMenu_SelectionItem {  padding-right: 1em;}
.CtxtMenu_Selection {  right: 40%; width:50%; }
.CtxtMenu_SelectionBox {  padding: 0em; max-height:20em; max-width: none;  background-color:#FFFFFF;}
.CtxtMenu_SelectionDivider {  clear: both; border-top: 2px solid #000000;}
.CtxtMenu_Menu .CtxtMenu_MenuClose {  top:-10px; left:-10px}
</style>

<style id="MJX-CHTML-styles">
mjx-container[jax="CHTML"] {
  line-height: 0;
}

mjx-container [space="1"] {
  margin-left: .111em;
}

mjx-container [space="2"] {
  margin-left: .167em;
}

mjx-container [space="3"] {
  margin-left: .222em;
}

mjx-container [space="4"] {
  margin-left: .278em;
}

mjx-container [space="5"] {
  margin-left: .333em;
}

mjx-container [rspace="1"] {
  margin-right: .111em;
}

mjx-container [rspace="2"] {
  margin-right: .167em;
}

mjx-container [rspace="3"] {
  margin-right: .222em;
}

mjx-container [rspace="4"] {
  margin-right: .278em;
}

mjx-container [rspace="5"] {
  margin-right: .333em;
}

mjx-container [size="s"] {
  font-size: 70.7%;
}

mjx-container [size="ss"] {
  font-size: 50%;
}

mjx-container [size="Tn"] {
  font-size: 60%;
}

mjx-container [size="sm"] {
  font-size: 85%;
}

mjx-container [size="lg"] {
  font-size: 120%;
}

mjx-container [size="Lg"] {
  font-size: 144%;
}

mjx-container [size="LG"] {
  font-size: 173%;
}

mjx-container [size="hg"] {
  font-size: 207%;
}

mjx-container [size="HG"] {
  font-size: 249%;
}

mjx-container [width="full"] {
  width: 100%;
}

mjx-box {
  display: inline-block;
}

mjx-block {
  display: block;
}

mjx-itable {
  display: inline-table;
}

mjx-row {
  display: table-row;
}

mjx-row > * {
  display: table-cell;
}

mjx-mtext {
  display: inline-block;
  text-align: left;
}

mjx-mstyle {
  display: inline-block;
}

mjx-merror {
  display: inline-block;
  color: red;
  background-color: yellow;
}

mjx-mphantom {
  visibility: hidden;
}

_::-webkit-full-page-media, _:future, :root mjx-container {
  will-change: opacity;
}

mjx-assistive-mml {
  position: absolute !important;
  top: 0px;
  left: 0px;
  clip: rect(1px, 1px, 1px, 1px);
  padding: 1px 0px 0px 0px !important;
  border: 0px !important;
  display: block !important;
  width: auto !important;
  overflow: hidden !important;
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

mjx-assistive-mml[display="block"] {
  width: 100% !important;
}

mjx-math {
  display: inline-block;
  text-align: left;
  line-height: 0;
  text-indent: 0;
  font-style: normal;
  font-weight: normal;
  font-size: 100%;
  font-size-adjust: none;
  letter-spacing: normal;
  border-collapse: collapse;
  word-wrap: normal;
  word-spacing: normal;
  white-space: nowrap;
  direction: ltr;
  padding: 1px 0;
}

mjx-container[jax="CHTML"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="CHTML"][display="true"][width="full"] {
  display: flex;
}

mjx-container[jax="CHTML"][display="true"] mjx-math {
  padding: 0;
}

mjx-container[jax="CHTML"][justify="left"] {
  text-align: left;
}

mjx-container[jax="CHTML"][justify="right"] {
  text-align: right;
}

mjx-mi {
  display: inline-block;
  text-align: left;
}

mjx-c {
  display: inline-block;
}

mjx-utext {
  display: inline-block;
  padding: .75em 0 .2em 0;
}

mjx-mo {
  display: inline-block;
  text-align: left;
}

mjx-stretchy-h {
  display: inline-table;
  width: 100%;
}

mjx-stretchy-h > * {
  display: table-cell;
  width: 0;
}

mjx-stretchy-h > * > mjx-c {
  display: inline-block;
  transform: scalex(1.0000001);
}

mjx-stretchy-h > * > mjx-c::before {
  display: inline-block;
  width: initial;
}

mjx-stretchy-h > mjx-ext {
  /* IE */ overflow: hidden;
  /* others */ overflow: clip visible;
  width: 100%;
}

mjx-stretchy-h > mjx-ext > mjx-c::before {
  transform: scalex(500);
}

mjx-stretchy-h > mjx-ext > mjx-c {
  width: 0;
}

mjx-stretchy-h > mjx-beg > mjx-c {
  margin-right: -.1em;
}

mjx-stretchy-h > mjx-end > mjx-c {
  margin-left: -.1em;
}

mjx-stretchy-v {
  display: inline-block;
}

mjx-stretchy-v > * {
  display: block;
}

mjx-stretchy-v > mjx-beg {
  height: 0;
}

mjx-stretchy-v > mjx-end > mjx-c {
  display: block;
}

mjx-stretchy-v > * > mjx-c {
  transform: scaley(1.0000001);
  transform-origin: left center;
  overflow: hidden;
}

mjx-stretchy-v > mjx-ext {
  display: block;
  height: 100%;
  box-sizing: border-box;
  border: 0px solid transparent;
  /* IE */ overflow: hidden;
  /* others */ overflow: visible clip;
}

mjx-stretchy-v > mjx-ext > mjx-c::before {
  width: initial;
  box-sizing: border-box;
}

mjx-stretchy-v > mjx-ext > mjx-c {
  transform: scaleY(500) translateY(.075em);
  overflow: visible;
}

mjx-mark {
  display: inline-block;
  height: 0px;
}

mjx-mfrac {
  display: inline-block;
  text-align: left;
}

mjx-frac {
  display: inline-block;
  vertical-align: 0.17em;
  padding: 0 .22em;
}

mjx-frac[type="d"] {
  vertical-align: .04em;
}

mjx-frac[delims] {
  padding: 0 .1em;
}

mjx-frac[atop] {
  padding: 0 .12em;
}

mjx-frac[atop][delims] {
  padding: 0;
}

mjx-dtable {
  display: inline-table;
  width: 100%;
}

mjx-dtable > * {
  font-size: 2000%;
}

mjx-dbox {
  display: block;
  font-size: 5%;
}

mjx-num {
  display: block;
  text-align: center;
}

mjx-den {
  display: block;
  text-align: center;
}

mjx-mfrac[bevelled] > mjx-num {
  display: inline-block;
}

mjx-mfrac[bevelled] > mjx-den {
  display: inline-block;
}

mjx-den[align="right"], mjx-num[align="right"] {
  text-align: right;
}

mjx-den[align="left"], mjx-num[align="left"] {
  text-align: left;
}

mjx-nstrut {
  display: inline-block;
  height: .054em;
  width: 0;
  vertical-align: -.054em;
}

mjx-nstrut[type="d"] {
  height: .217em;
  vertical-align: -.217em;
}

mjx-dstrut {
  display: inline-block;
  height: .505em;
  width: 0;
}

mjx-dstrut[type="d"] {
  height: .726em;
}

mjx-line {
  display: block;
  box-sizing: border-box;
  min-height: 1px;
  height: .06em;
  border-top: .06em solid;
  margin: .06em -.1em;
  overflow: hidden;
}

mjx-line[type="d"] {
  margin: .18em -.1em;
}

mjx-c::before {
  display: block;
  width: 0;
}

.MJX-TEX {
  font-family: MJXZERO, MJXTEX;
}

.TEX-B {
  font-family: MJXZERO, MJXTEX-B;
}

.TEX-I {
  font-family: MJXZERO, MJXTEX-I;
}

.TEX-MI {
  font-family: MJXZERO, MJXTEX-MI;
}

.TEX-BI {
  font-family: MJXZERO, MJXTEX-BI;
}

.TEX-S1 {
  font-family: MJXZERO, MJXTEX-S1;
}

.TEX-S2 {
  font-family: MJXZERO, MJXTEX-S2;
}

.TEX-S3 {
  font-family: MJXZERO, MJXTEX-S3;
}

.TEX-S4 {
  font-family: MJXZERO, MJXTEX-S4;
}

.TEX-A {
  font-family: MJXZERO, MJXTEX-A;
}

.TEX-C {
  font-family: MJXZERO, MJXTEX-C;
}

.TEX-CB {
  font-family: MJXZERO, MJXTEX-CB;
}

.TEX-FR {
  font-family: MJXZERO, MJXTEX-FR;
}

.TEX-FRB {
  font-family: MJXZERO, MJXTEX-FRB;
}

.TEX-SS {
  font-family: MJXZERO, MJXTEX-SS;
}

.TEX-SSB {
  font-family: MJXZERO, MJXTEX-SSB;
}

.TEX-SSI {
  font-family: MJXZERO, MJXTEX-SSI;
}

.TEX-SC {
  font-family: MJXZERO, MJXTEX-SC;
}

.TEX-T {
  font-family: MJXZERO, MJXTEX-T;
}

.TEX-V {
  font-family: MJXZERO, MJXTEX-V;
}

.TEX-VB {
  font-family: MJXZERO, MJXTEX-VB;
}

mjx-stretchy-v mjx-c, mjx-stretchy-h mjx-c {
  font-family: MJXZERO, MJXTEX-S1, MJXTEX-S4, MJXTEX, MJXTEX-A ! important;
}

@font-face /* 0 */ {
  font-family: MJXZERO;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Zero.woff") format("woff");
}

@font-face /* 1 */ {
  font-family: MJXTEX;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Main-Regular.woff") format("woff");
}

@font-face /* 2 */ {
  font-family: MJXTEX-B;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Main-Bold.woff") format("woff");
}

@font-face /* 3 */ {
  font-family: MJXTEX-I;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Math-Italic.woff") format("woff");
}

@font-face /* 4 */ {
  font-family: MJXTEX-MI;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Main-Italic.woff") format("woff");
}

@font-face /* 5 */ {
  font-family: MJXTEX-BI;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Math-BoldItalic.woff") format("woff");
}

@font-face /* 6 */ {
  font-family: MJXTEX-S1;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Size1-Regular.woff") format("woff");
}

@font-face /* 7 */ {
  font-family: MJXTEX-S2;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Size2-Regular.woff") format("woff");
}

@font-face /* 8 */ {
  font-family: MJXTEX-S3;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Size3-Regular.woff") format("woff");
}

@font-face /* 9 */ {
  font-family: MJXTEX-S4;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Size4-Regular.woff") format("woff");
}

@font-face /* 10 */ {
  font-family: MJXTEX-A;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_AMS-Regular.woff") format("woff");
}

@font-face /* 11 */ {
  font-family: MJXTEX-C;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Calligraphic-Regular.woff") format("woff");
}

@font-face /* 12 */ {
  font-family: MJXTEX-CB;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Calligraphic-Bold.woff") format("woff");
}

@font-face /* 13 */ {
  font-family: MJXTEX-FR;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Fraktur-Regular.woff") format("woff");
}

@font-face /* 14 */ {
  font-family: MJXTEX-FRB;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Fraktur-Bold.woff") format("woff");
}

@font-face /* 15 */ {
  font-family: MJXTEX-SS;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_SansSerif-Regular.woff") format("woff");
}

@font-face /* 16 */ {
  font-family: MJXTEX-SSB;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_SansSerif-Bold.woff") format("woff");
}

@font-face /* 17 */ {
  font-family: MJXTEX-SSI;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_SansSerif-Italic.woff") format("woff");
}

@font-face /* 18 */ {
  font-family: MJXTEX-SC;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Script-Regular.woff") format("woff");
}

@font-face /* 19 */ {
  font-family: MJXTEX-T;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Typewriter-Regular.woff") format("woff");
}

@font-face /* 20 */ {
  font-family: MJXTEX-V;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Vector-Regular.woff") format("woff");
}

@font-face /* 21 */ {
  font-family: MJXTEX-VB;
  src: url("https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Vector-Bold.woff") format("woff");
}

mjx-c.mjx-c1D447.TEX-I::before {
  padding: 0.677em 0.704em 0 0;
  content: "T";
}

mjx-c.mjx-c1D439.TEX-I::before {
  padding: 0.68em 0.749em 0 0;
  content: "F";
}

mjx-c.mjx-c3D::before {
  padding: 0.583em 0.778em 0.082em 0;
  content: "=";
}

mjx-c.mjx-c6E::before {
  padding: 0.442em 0.556em 0 0;
  content: "n";
}

mjx-c.mjx-c75::before {
  padding: 0.442em 0.556em 0.011em 0;
  content: "u";
}

mjx-c.mjx-c6D::before {
  padding: 0.442em 0.833em 0 0;
  content: "m";
}

mjx-c.mjx-c62::before {
  padding: 0.694em 0.556em 0.011em 0;
  content: "b";
}

mjx-c.mjx-c65::before {
  padding: 0.448em 0.444em 0.011em 0;
  content: "e";
}

mjx-c.mjx-c72::before {
  padding: 0.442em 0.392em 0 0;
  content: "r";
}

mjx-c.mjx-c20::before {
  padding: 0 0.25em 0 0;
  content: " ";
}

mjx-c.mjx-c6F::before {
  padding: 0.448em 0.5em 0.01em 0;
  content: "o";
}

mjx-c.mjx-c66::before {
  padding: 0.705em 0.372em 0 0;
  content: "f";
}

mjx-c.mjx-c74::before {
  padding: 0.615em 0.389em 0.01em 0;
  content: "t";
}

mjx-c.mjx-c69::before {
  padding: 0.669em 0.278em 0 0;
  content: "i";
}

mjx-c.mjx-c73::before {
  padding: 0.448em 0.394em 0.011em 0;
  content: "s";
}

mjx-c.mjx-c68::before {
  padding: 0.694em 0.556em 0 0;
  content: "h";
}

mjx-c.mjx-c61::before {
  padding: 0.448em 0.5em 0.011em 0;
  content: "a";
}

mjx-c.mjx-c70::before {
  padding: 0.442em 0.556em 0.194em 0;
  content: "p";
}

mjx-c.mjx-c64::before {
  padding: 0.694em 0.556em 0.011em 0;
  content: "d";
}

mjx-c.mjx-c63::before {
  padding: 0.448em 0.444em 0.011em 0;
  content: "c";
}

mjx-c.mjx-c6C::before {
  padding: 0.694em 0.278em 0 0;
  content: "l";
}

mjx-c.mjx-c77::before {
  padding: 0.431em 0.722em 0.011em 0;
  content: "w";
}

mjx-c.mjx-c1D43C.TEX-I::before {
  padding: 0.683em 0.504em 0 0;
  content: "I";
}

mjx-c.mjx-c1D437.TEX-I::before {
  padding: 0.683em 0.828em 0 0;
  content: "D";
}

mjx-c.mjx-c54::before {
  padding: 0.677em 0.722em 0 0;
  content: "T";
}

mjx-c.mjx-c46::before {
  padding: 0.68em 0.653em 0 0;
  content: "F";
}

mjx-c.mjx-c2D::before {
  padding: 0.252em 0.333em 0 0;
  content: "-";
}

mjx-c.mjx-c49::before {
  padding: 0.683em 0.361em 0 0;
  content: "I";
}

mjx-c.mjx-c44::before {
  padding: 0.683em 0.764em 0 0;
  content: "D";
}

mjx-c.mjx-c2217::before {
  padding: 0.465em 0.5em 0 0;
  content: "\2217";
}
</style></head>

<body class="quarto-light">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-full toc-left">
<div id="quarto-sidebar-toc-left" class="sidebar toc-left">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#dataset-description" id="toc-dataset-description" class="nav-link" data-scroll-target="#dataset-description">Dataset Description</a></li>
  <li><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#preprocessing" id="toc-preprocessing" class="nav-link" data-scroll-target="#preprocessing">Preprocessing</a>
  <ul class="collapse">
  <li><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#preprocessing-function-our-recipe" id="toc-preprocessing-function-our-recipe" class="nav-link" data-scroll-target="#preprocessing-function-our-recipe">Preprocessing Function (Our recipe):</a></li>
  </ul></li>
  <li><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#explanatory-data-analysis" id="toc-explanatory-data-analysis" class="nav-link" data-scroll-target="#explanatory-data-analysis">Explanatory Data Analysis</a>
  <ul class="collapse">
  <li><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#frequency-distribution" id="toc-frequency-distribution" class="nav-link" data-scroll-target="#frequency-distribution">Frequency Distribution</a></li>
  <li><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#wordcloud" id="toc-wordcloud" class="nav-link" data-scroll-target="#wordcloud">Wordcloud</a></li>
  </ul></li>
  <li><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#train-and-test-split" id="toc-train-and-test-split" class="nav-link" data-scroll-target="#train-and-test-split">Train and Test split</a></li>
  <li><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#feature-extraction" id="toc-feature-extraction" class="nav-link" data-scroll-target="#feature-extraction">Feature Extraction</a>
  <ul class="collapse">
  <li><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#word-embedding" id="toc-word-embedding" class="nav-link" data-scroll-target="#word-embedding">Word Embedding</a>
  <ul class="collapse">
  <li><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#bag-of-words-count-vectorizer" id="toc-bag-of-words-count-vectorizer" class="nav-link" data-scroll-target="#bag-of-words-count-vectorizer">Bag of Words (count vectorizer)</a></li>
  <li><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#tf-idf-term-frequency---inverse-document-frequency" id="toc-tf-idf-term-frequency---inverse-document-frequency" class="nav-link" data-scroll-target="#tf-idf-term-frequency---inverse-document-frequency">TF-IDF (Term Frequency - Inverse Document Frequency)</a></li>
  <li><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#word2vec" id="toc-word2vec" class="nav-link" data-scroll-target="#word2vec">Word2Vec</a></li>
  <li><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#more-vizualizations-t-sne-t-distributed-stochastic-neighbor-embedding" id="toc-more-vizualizations-t-sne-t-distributed-stochastic-neighbor-embedding" class="nav-link" data-scroll-target="#more-vizualizations-t-sne-t-distributed-stochastic-neighbor-embedding">More Vizualizations: t-SNE (t-distributed Stochastic Neighbor Embedding)</a></li>
  <li><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#doc2vec" id="toc-doc2vec" class="nav-link" data-scroll-target="#doc2vec">Doc2Vec</a></li>
  </ul></li>
  </ul></li>
  <li><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#modelling" id="toc-modelling" class="nav-link" data-scroll-target="#modelling">Modelling</a>
  <ul class="collapse">
  <li><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#model-fitting-with-hyperparameter-tuning-using-gridsearchcv" id="toc-model-fitting-with-hyperparameter-tuning-using-gridsearchcv" class="nav-link" data-scroll-target="#model-fitting-with-hyperparameter-tuning-using-gridsearchcv">Model Fitting with Hyperparameter tuning using GridSearchCV:</a></li>
  <li><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#logistic-regression-w-penalty" id="toc-logistic-regression-w-penalty" class="nav-link" data-scroll-target="#logistic-regression-w-penalty">Logistic Regression w/ Penalty</a></li>
  <li><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#support-vector-machines" id="toc-support-vector-machines" class="nav-link" data-scroll-target="#support-vector-machines">Support Vector Machines</a></li>
  <li><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#k-nearest-neighbors" id="toc-k-nearest-neighbors" class="nav-link" data-scroll-target="#k-nearest-neighbors">K-Nearest neighbors</a></li>
  <li><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#random-forest-classifier" id="toc-random-forest-classifier" class="nav-link" data-scroll-target="#random-forest-classifier">Random Forest Classifier</a></li>
  <li><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#the-best-model" id="toc-the-best-model" class="nav-link" data-scroll-target="#the-best-model">The Best Model</a></li>
  </ul></li>
  <li><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  </ul>
</nav>
</div>
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
</div>
<main class="content column-page-right" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Sentimental Analysis on Amazon Reviews</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Nealson Setiawan </p>
          </div>
  </div>
    
  
    
  </div>
  

</header>

<section id="loading-packages" class="level5">
<h5 class="anchored" data-anchor-id="loading-packages">Loading Packages<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#loading-packages" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h5>
<div class="cell" data-execution_count="1">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb1-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> re</span>
<span id="cb1-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datasets <span class="im">import</span> load_dataset</span>
<span id="cb1-4"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> Markdown</span>
<span id="cb1-6"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tabulate <span class="im">import</span> tabulate</span>
<span id="cb1-7"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb1-9"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-11"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-12"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb1-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-13"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> jupyterthemes <span class="im">as</span> jt</span>
<span id="cb1-14"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> jupyterthemes.stylefx <span class="im">import</span> set_nb_theme</span>
<span id="cb1-15"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pickle</span>
<span id="cb1-17"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb1-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-18"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> nltk</span>
<span id="cb1-19"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.collocations <span class="im">import</span> <span class="op">*</span></span>
<span id="cb1-20"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.stem <span class="im">import</span> WordNetLemmatizer</span>
<span id="cb1-21"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.tokenize <span class="im">import</span> RegexpTokenizer</span>
<span id="cb1-22"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.probability <span class="im">import</span> FreqDist</span>
<span id="cb1-23"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.corpus <span class="im">import</span> stopwords</span>
<span id="cb1-24"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb1-24" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.stem.wordnet <span class="im">import</span> WordNetLemmatizer</span>
<span id="cb1-25"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb1-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-26"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb1-26" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> gensim.models <span class="im">import</span> word2vec</span>
<span id="cb1-27"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb1-27" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> gensim.models.doc2vec <span class="im">import</span> Doc2Vec, TaggedDocument</span>
<span id="cb1-28"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb1-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-29"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb1-29" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> wordcloud <span class="im">import</span> WordCloud, ImageColorGenerator</span>
<span id="cb1-30"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb1-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-31"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb1-31" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-32"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb1-32" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-33"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb1-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-34"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb1-34" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> FunctionTransformer</span>
<span id="cb1-35"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb1-35" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> Pipeline</span>
<span id="cb1-36"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb1-36" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score</span>
<span id="cb1-37"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb1-37" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix</span>
<span id="cb1-38"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb1-38" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb1-39"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb1-39" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> cross_val_score, cross_validate</span>
<span id="cb1-40"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb1-40" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> GridSearchCV</span>
<span id="cb1-41"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb1-41" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> CountVectorizer</span>
<span id="cb1-42"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb1-42" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> TfidfVectorizer</span>
<span id="cb1-43"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb1-43" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.manifold <span class="im">import</span> TSNE</span>
<span id="cb1-44"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb1-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-45"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb1-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-46"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb1-46" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> SVC</span>
<span id="cb1-47"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb1-47" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb1-48"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb1-48" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> KNeighborsClassifier</span>
<span id="cb1-49"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb1-49" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier</span>
<span id="cb1-50"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb1-50" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> RidgeClassifier</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>Hello Reader! I am doing sentimental analysis on Amazon reviews.</p>
<p>This is a Natural Language Processing, or NLP, project and requires processing text data. I decided to do my project on NLP and on Python as I felt I was too familiar with R from the classes and I wanted to learn more Python and a new field in Data Science. Also, I am using Quarto markdown, which is a multi-language markdown software for R and Python. I used Quarto because honestly, Jupyter notebook doesn’t look as good as R markdown.</p>
<p>Also, throughout the report, I will use a package called pickle to read and save data.</p>
<p>Nonetheless, I hope you get to learn something along the way!</p>
<p>Now let’s start with the Dataset!</p>
</section>
<section id="dataset-description" class="level1">
<h1>Dataset Description</h1>
<p>The dataset consists of 4 million rows of Amazon Reviews with respective labels consisting of 0: negative, and 1: positive. Because the file is too large, it’s better to download the data immediately from Hugging Face itself, as I won’t include the data in the zip file.</p>
<p>Link: <a href="https://huggingface.co/datasets/amazon_polarity">Amazon_Polarity_Dataset</a></p>
<p><strong>Codebook:</strong></p>
<ol type="1">
<li>Label: Sentiment of the review
<ul>
<li><p>0: negative</p></li>
<li><p>1: positive</p></li>
</ul></li>
<li>Title: Title of the review</li>
<li>Content: the body of the review</li>
</ol>
<p><strong>Download from Hugging Face website:</strong></p>
<div class="cell" data-execution_count="2">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># #download the dataset from Hugging Face</span></span>
<span id="cb2-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="co"># df_train = load_dataset("amazon_polarity", split='train')</span></span>
<span id="cb2-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co"># df_test = load_dataset('amazon_polarity', split='test')</span></span>
<span id="cb2-4"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co"># </span></span>
<span id="cb2-5"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="co"># train = df_train.to_pandas()</span></span>
<span id="cb2-6"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="co"># test = df_test.to_pandas()</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Converting it into one dataset. Since I frankly don’t have enough computational power, I won’t use the title column and hence, I will drop it. Honestly, the original dataframe has 4 million observations. It is like ~1GB of data. I cannot submit this, so I will reduce it to 4000 (2000 per label).</p>
<div class="cell" data-execution_count="3">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co">'''</span></span>
<span id="cb3-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="co">df = pd.concat([train,test]) #make to one dataframe</span></span>
<span id="cb3-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co">df = df.drop('title', axis=1) #drop title since we're only using content and label</span></span>
<span id="cb3-5"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="co">'''</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="3">
<pre><code>"\ndf = pd.concat([train,test]) #make to one dataframe\n\ndf = df.drop('title', axis=1) #drop title since we're only using content and label\n"</code></pre>
</div>
</div>
<p>The dataset now consists of 4 million reviews and 2 columns (label and content).</p>
<p><strong>Label distribution in the original dataset:</strong></p>
<div class="cell" data-execution_count="4">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co">'''</span></span>
<span id="cb5-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="co"># set the color palette we want to use for our vizualtions</span></span>
<span id="cb5-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="co"># i used the color palette called "Beach House" from </span></span>
<span id="cb5-4"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="co">col = ('#fe4a49', '#2ab7ca','#fed766','#e6e6ea','#f4f4f8')</span></span>
<span id="cb5-5"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb5-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-6"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="co">fig = plt.figure(figsize=(10, 10))</span></span>
<span id="cb5-7"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="co">sns_plot = sns.countplot(x='label',data=df, palette=col).set(title='Distribution of labels in original dataset')</span></span>
<span id="cb5-8"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="co">plt.savefig("figures/df_label_distribution.png", format='png')</span></span>
<span id="cb5-9"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb5-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-10"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="co">#save the image object as a pickle file</span></span>
<span id="cb5-11"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb5-11" aria-hidden="true" tabindex="-1"></a><span class="co">with open('figures/pickle_data/df_label_distribution.pickle', 'wb') as f:</span></span>
<span id="cb5-12"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb5-12" aria-hidden="true" tabindex="-1"></a><span class="co">    pickle.dump(fig, f)</span></span>
<span id="cb5-13"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb5-13" aria-hidden="true" tabindex="-1"></a><span class="co">'''</span></span>
<span id="cb5-14"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb5-14" aria-hidden="true" tabindex="-1"></a><span class="co">#save the image object as a pickle file</span></span>
<span id="cb5-15"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb5-15" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(<span class="st">'figures/pickle_data/df_label_distribution.pickle'</span>, <span class="st">'rb'</span>) <span class="im">as</span> f:</span>
<span id="cb5-16"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb5-16" aria-hidden="true" tabindex="-1"></a>    fig <span class="op">=</span> pickle.load(f)</span>
<span id="cb5-17"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb5-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-18"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb5-18" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="./Report_files/cell-5-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>As you can see, there is a fair distribution of labels in the original dataset.</p>
<div class="cell" data-execution_count="5">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># randomly sample 1000 observations from each group of labels (0 and 1)</span></span>
<span id="cb6-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb6-2" aria-hidden="true" tabindex="-1"></a>seed <span class="op">=</span> <span class="dv">19923839</span></span>
<span id="cb6-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb6-3" aria-hidden="true" tabindex="-1"></a>random.seed(seed)</span>
<span id="cb6-4"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="co">'''</span></span>
<span id="cb6-5"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="co">df_reduced = df.groupby('label', group_keys=False).apply(lambda x: x.sample(2000))</span></span>
<span id="cb6-6"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb6-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-7"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb6-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-8"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="co">#let's save the data to make it easier to load later</span></span>
<span id="cb6-9"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="co">df_reduced.to_csv('data/unprocessed/df_reduced.csv')</span></span>
<span id="cb6-10"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb6-10" aria-hidden="true" tabindex="-1"></a><span class="co">df_reduced.to_pickle('data/unprocessed/df_reduced.pickle')</span></span>
<span id="cb6-11"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb6-11" aria-hidden="true" tabindex="-1"></a><span class="co">'''</span></span>
<span id="cb6-12"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb6-12" aria-hidden="true" tabindex="-1"></a>df_reduced <span class="op">=</span> pd.read_pickle(<span class="st">'data/unprocessed/df_reduced.pickle'</span>)</span>
<span id="cb6-13"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb6-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-14"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb6-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'The shape of the reduced dataset is: </span><span class="sc">{}</span><span class="st">'</span>.<span class="bu">format</span>(df_reduced.shape))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>The shape of the reduced dataset is: (4000, 2)</code></pre>
</div>
</div>
<p>Now it only consists of 4000 reviews. We will only use this dataset for the rest of the project. This will help with computation later.</p>
<p><strong>Missing Data:</strong></p>
<div class="cell" data-execution_count="6">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'The dataset has </span><span class="sc">{}</span><span class="st"> missing values.'</span>.<span class="bu">format</span>(df_reduced.isna().<span class="bu">sum</span>().values[<span class="dv">0</span>]))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>The dataset has 0 missing values.</code></pre>
</div>
</div>
<p>That’s actually amazing. There isn’t any missing data.</p>
<div class="cell" data-execution_count="7">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># set the color palette we want to use for our vizualtions</span></span>
<span id="cb10-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="co"># i used the color palette called "Beach House" from </span></span>
<span id="cb10-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb10-3" aria-hidden="true" tabindex="-1"></a>col <span class="op">=</span> (<span class="st">'#fe4a49'</span>, <span class="st">'#2ab7ca'</span>,<span class="st">'#fed766'</span>,<span class="st">'#e6e6ea'</span>,<span class="st">'#f4f4f8'</span>)</span>
<span id="cb10-4"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb10-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-5"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb10-5" aria-hidden="true" tabindex="-1"></a>sns.countplot(x<span class="op">=</span><span class="st">'label'</span>,data<span class="op">=</span>df_reduced,palette<span class="op">=</span>col).<span class="bu">set</span>(title<span class="op">=</span><span class="st">'Distribution of labels in the reduced dataset'</span>)</span>
<span id="cb10-6"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb10-6" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="./Report_files/cell-8-output-1.png" width="602" height="449"></p>
</div>
</div>
<p>As you can see, there is a even distribution of labels in the reduced dataset!</p>
</section>
<section id="preprocessing" class="level1">
<h1>Preprocessing</h1>
<p>Preprocessing checklist:</p>
<ol type="1">
<li>Lowercase text</li>
<li>Strip unwanted characters from text, like punctuation and numbers</li>
<li>Tokenize</li>
<li>Lemmatize</li>
<li>Remove stopwords</li>
</ol>
<p><strong>Explanation</strong></p>
<p>We want the text to be in a consistent universal form. This is why we <strong>lowercase, and remove any unwanted characters</strong> as punctuation and numbers don’t really affect sentimental values in my opinion.</p>
<p>Afterwards, we have to seperate the text into a list of their individual words. This is called <strong>tokenizing</strong>.</p>
<p>Next, if you notice, there are words like flying which has the same meaning as fly. We want to convert this to make the text in a consistent manner. There are multiple ways to do this. One way is to stem the text, which is to convert each word into their root word. So it will convert fly and flying to fli. However, this removes some meaning in the conversion. So, I will use what’s called <strong><em>lemmatization</em></strong>, where words like flying will be converted into their non-grammar word like flying to fly and lying to lie.</p>
<p>Finally, there are some words in the text that doesn’t really contain any meaning like ‘i’ and ‘then’. These are called <strong>stopwords</strong>. We want to remove it. There’s a lot of list of stopwords in the internet, but I will use the english stopwords from the scikitlearn package.</p>
<p>Let’s make a function to make this easier to apply to every row of the dataset. This will act as our recipe.</p>
<section id="preprocessing-function-our-recipe" class="level2">
<h2 class="anchored" data-anchor-id="preprocessing-function-our-recipe">Preprocessing Function (Our recipe):<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#preprocessing-function-our-recipe" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>
<div class="cell" data-execution_count="8">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co">#let's create a function to apply to every row of the training set</span></span>
<span id="cb11-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="co">#this acts as a recipe we can feed into the word embedder later!</span></span>
<span id="cb11-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb11-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-4"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> preprocess_text(s, stopwords<span class="op">=</span><span class="bu">list</span>(stopwords.words(<span class="st">"english"</span>)), lem<span class="op">=</span>WordNetLemmatizer()):</span>
<span id="cb11-5"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb11-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-6"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb11-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># lowercase our text</span></span>
<span id="cb11-7"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb11-7" aria-hidden="true" tabindex="-1"></a>    t <span class="op">=</span> s.lower()</span>
<span id="cb11-8"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb11-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-9"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb11-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">''' tokenize and strip punctuation using regex tokenizing</span></span>
<span id="cb11-10"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb11-10" aria-hidden="true" tabindex="-1"></a><span class="co">    since we lower all characters before, we are only keeping </span></span>
<span id="cb11-11"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb11-11" aria-hidden="true" tabindex="-1"></a><span class="co">    letters and disregarding punctuations and number, since I think </span></span>
<span id="cb11-12"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb11-12" aria-hidden="true" tabindex="-1"></a><span class="co">    numbers won't affect sentiment. '''</span></span>
<span id="cb11-13"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb11-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-14"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb11-14" aria-hidden="true" tabindex="-1"></a>    <span class="co">#tokenize and strip punct</span></span>
<span id="cb11-15"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb11-15" aria-hidden="true" tabindex="-1"></a>    regToken <span class="op">=</span> RegexpTokenizer(<span class="vs">r'[0-9]+|\s+|[.,\/#!$%\^&amp;\*;:</span><span class="sc">{}</span><span class="vs">=\-_`~()"]+'</span>, gaps<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb11-16"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb11-16" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-17"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb11-17" aria-hidden="true" tabindex="-1"></a>    <span class="co">#tokenize</span></span>
<span id="cb11-18"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb11-18" aria-hidden="true" tabindex="-1"></a>    t <span class="op">=</span> regToken.tokenize(t)</span>
<span id="cb11-19"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb11-19" aria-hidden="true" tabindex="-1"></a>       </span>
<span id="cb11-20"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb11-20" aria-hidden="true" tabindex="-1"></a>    <span class="co">#create the stop_words list from inputted stopwords list</span></span>
<span id="cb11-21"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb11-21" aria-hidden="true" tabindex="-1"></a>    stop_words <span class="op">=</span> <span class="bu">list</span>(stopwords)</span>
<span id="cb11-22"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb11-22" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-23"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb11-23" aria-hidden="true" tabindex="-1"></a>    <span class="co">#create an empty container</span></span>
<span id="cb11-24"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb11-24" aria-hidden="true" tabindex="-1"></a>    t_filtered <span class="op">=</span> []</span>
<span id="cb11-25"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb11-25" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-26"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb11-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># for loop to only keep words not in the stopwords list</span></span>
<span id="cb11-27"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb11-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># and lemmatize the word</span></span>
<span id="cb11-28"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb11-28" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> t:</span>
<span id="cb11-29"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb11-29" aria-hidden="true" tabindex="-1"></a>        i <span class="op">=</span> re.sub(<span class="vs">r"'.+"</span>,<span class="st">""</span>,i)</span>
<span id="cb11-30"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb11-30" aria-hidden="true" tabindex="-1"></a>        t_lem <span class="op">=</span> lem.lemmatize(i)</span>
<span id="cb11-31"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb11-31" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> i <span class="kw">not</span> <span class="kw">in</span> stop_words:</span>
<span id="cb11-32"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb11-32" aria-hidden="true" tabindex="-1"></a>            t_filtered.append(t_lem)</span>
<span id="cb11-33"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb11-33" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb11-34"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb11-34" aria-hidden="true" tabindex="-1"></a>    t <span class="op">=</span> t_filtered</span>
<span id="cb11-35"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb11-35" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-36"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb11-36" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-37"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb11-37" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> t</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Let’s try applying it to our dataset, and assign it into a new column called clean.</p>
<div class="cell" data-execution_count="9">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co">#using .apply() we can apply this function to every row in the content column</span></span>
<span id="cb12-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb12-2" aria-hidden="true" tabindex="-1"></a>df_reduced[<span class="st">'clean'</span>] <span class="op">=</span> df_reduced[<span class="st">'content'</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: preprocess_text(x)) <span class="co">#assign it to a clean column</span></span>
<span id="cb12-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb12-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-4"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="co">#save our reduced dataframe to a csv</span></span>
<span id="cb12-5"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb12-5" aria-hidden="true" tabindex="-1"></a>df_reduced.to_csv(<span class="st">'data/processed/df_reduced_clean.csv'</span>)</span>
<span id="cb12-6"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb12-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-7"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb12-7" aria-hidden="true" tabindex="-1"></a><span class="co">#let's save the reduced data to a pickle to load later</span></span>
<span id="cb12-8"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb12-8" aria-hidden="true" tabindex="-1"></a>df_reduced.to_pickle(<span class="st">'data/processed/df_reduced_clean.pickle'</span>)</span>
<span id="cb12-9"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb12-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-10"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb12-10" aria-hidden="true" tabindex="-1"></a><span class="co">#read the reduced dataframe as a pickle</span></span>
<span id="cb12-11"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb12-11" aria-hidden="true" tabindex="-1"></a>df_reduced <span class="op">=</span> pd.read_pickle(<span class="st">'data/processed/df_reduced.pickle'</span>)</span>
<span id="cb12-12"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb12-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-13"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb12-13" aria-hidden="true" tabindex="-1"></a>df_reduced.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="9">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>label</th>
      <th>content</th>
      <th>clean</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2167315</th>
      <td>0</td>
      <td>I bought this thinking it'd be sleek and decen...</td>
      <td>[bought, thinking, sleek, decently, useful, bo...</td>
    </tr>
    <tr>
      <th>2605225</th>
      <td>0</td>
      <td>I purchased 2 sets (one for me and one for the...</td>
      <td>[purchased, set, one, one, wife, couple, week,...</td>
    </tr>
    <tr>
      <th>768994</th>
      <td>0</td>
      <td>Two movies are blank....The king and I and Sou...</td>
      <td>[two, movie, blank, king, south, pacific, blac...</td>
    </tr>
    <tr>
      <th>1064969</th>
      <td>0</td>
      <td>If you're looking for a *replacement* carafe a...</td>
      <td>[looking, replacement, carafe, already, coffee...</td>
    </tr>
    <tr>
      <th>2157277</th>
      <td>0</td>
      <td>The first time I saw this I was sort of impres...</td>
      <td>[first, time, saw, sort, impressed, know, acti...</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
</section>
<section id="explanatory-data-analysis" class="level1">
<h1>Explanatory Data Analysis</h1>
<section id="frequency-distribution" class="level2">
<h2 class="anchored" data-anchor-id="frequency-distribution">Frequency Distribution<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#frequency-distribution" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>
<p>Let’s start with a frequency distribution. This is basically seeing which words occur the most often in the reviews. To do this we just add every token into a list and see which words comes up the most.</p>
<p>For this, I will use the FreqDist function from NLTK package, and take only the top 20 words</p>
<div class="cell" data-execution_count="10">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb13-1" aria-hidden="true" tabindex="-1"></a>word_list_all <span class="op">=</span> []</span>
<span id="cb13-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="co">#for every list in clean_X_train, add the values into word_list</span></span>
<span id="cb13-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb13-3" aria-hidden="true" tabindex="-1"></a>df_reduced[<span class="st">'clean'</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: word_list_all.extend(x))</span>
<span id="cb13-4"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb13-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-5"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="co">#keep only the top 20 most common words</span></span>
<span id="cb13-6"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb13-6" aria-hidden="true" tabindex="-1"></a>fdist_all <span class="op">=</span> FreqDist(word_list_all).most_common(<span class="dv">20</span>)</span>
<span id="cb13-7"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb13-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-8"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb13-8" aria-hidden="true" tabindex="-1"></a><span class="co">#convert to series to make it easier to plot</span></span>
<span id="cb13-9"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb13-9" aria-hidden="true" tabindex="-1"></a>fdist_all <span class="op">=</span> pd.Series(<span class="bu">dict</span>(fdist_all))</span>
<span id="cb13-10"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb13-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-11"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb13-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'There are </span><span class="sc">{}</span><span class="st"> cleaned words from all the reviews'</span>.<span class="bu">format</span>(<span class="bu">len</span>(word_list_all)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>There are 148784 cleaned words from all the reviews</code></pre>
</div>
</div>
<p>As you can see, there are 148784 words in the review after cleaning. Now let’s see the graph.</p>
<div class="cell" data-execution_count="11">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb15-1" aria-hidden="true" tabindex="-1"></a>sns.barplot(y<span class="op">=</span>fdist_all.index, x<span class="op">=</span>fdist_all.values, palette<span class="op">=</span>col)</span>
<span id="cb15-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb15-2" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Top 20 words in all reviews'</span>)</span>
<span id="cb15-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb15-3" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'count'</span>)</span>
<span id="cb15-4"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb15-4" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'word'</span>)</span>
<span id="cb15-5"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb15-5" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="./Report_files/cell-12-output-1.png" width="619" height="449"></p>
</div>
</div>
<p>From the Frequency distribution graph, we can see the word book, one, and like comes up a lot. It doesn’t look like there’s much information, but this might provide contextual information later when we perform word embedding, so we’ll keep it.</p>
<p>I honestly didn’t know there are so many book reviews. But since the reviews are pulled randomly from the Amazon, this might show that there are lots of books being sold in Amazon, or that book reviewers tend to give reviews the most. Or this could also provide insight to the bias in the sampling methods of the dataset from Amazon Reviews.</p>
<p>Nonetheless, let’s move on to the negative reviews.</p>
<p><strong>Negative reviews:</strong></p>
<div class="cell" data-execution_count="12">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co">#create two word list 0 and 1</span></span>
<span id="cb16-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb16-2" aria-hidden="true" tabindex="-1"></a>word_list_0 <span class="op">=</span> []</span>
<span id="cb16-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb16-3" aria-hidden="true" tabindex="-1"></a>word_list_1 <span class="op">=</span> []</span>
<span id="cb16-4"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb16-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-5"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb16-5" aria-hidden="true" tabindex="-1"></a><span class="co">#create a for loop, and do the same but conditioned on label value:</span></span>
<span id="cb16-6"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb16-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> df_reduced[<span class="st">'label'</span>].unique():</span>
<span id="cb16-7"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb16-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> i <span class="op">==</span><span class="dv">0</span>:</span>
<span id="cb16-8"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb16-8" aria-hidden="true" tabindex="-1"></a>        df_reduced.loc[df_reduced[<span class="st">'label'</span>]<span class="op">==</span>i][<span class="st">'clean'</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: word_list_0.extend(x))</span>
<span id="cb16-9"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb16-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb16-10"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb16-10" aria-hidden="true" tabindex="-1"></a>        df_reduced.loc[df_reduced[<span class="st">'label'</span>]<span class="op">==</span>i][<span class="st">'clean'</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: word_list_1.extend(x))</span>
<span id="cb16-11"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb16-11" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb16-12"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb16-12" aria-hidden="true" tabindex="-1"></a><span class="co"># keep only the top 20 words</span></span>
<span id="cb16-13"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb16-13" aria-hidden="true" tabindex="-1"></a>fdist_0 <span class="op">=</span> FreqDist(word_list_0).most_common(<span class="dv">20</span>)</span>
<span id="cb16-14"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb16-14" aria-hidden="true" tabindex="-1"></a>fdist_1 <span class="op">=</span> FreqDist(word_list_1).most_common(<span class="dv">20</span>)</span>
<span id="cb16-15"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb16-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-16"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb16-16" aria-hidden="true" tabindex="-1"></a><span class="co">#convert to series to make it easier to plot</span></span>
<span id="cb16-17"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb16-17" aria-hidden="true" tabindex="-1"></a>fdist_0 <span class="op">=</span> pd.Series(<span class="bu">dict</span>(fdist_0))</span>
<span id="cb16-18"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb16-18" aria-hidden="true" tabindex="-1"></a>fdist_1 <span class="op">=</span> pd.Series(<span class="bu">dict</span>(fdist_1))</span>
<span id="cb16-19"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb16-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-20"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb16-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'There are </span><span class="sc">{}</span><span class="st"> cleaned words from all the negative reviews'</span>.<span class="bu">format</span>(<span class="bu">len</span>(word_list_0)))</span>
<span id="cb16-21"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb16-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'There are </span><span class="sc">{}</span><span class="st"> cleaned words from all the positive reviews'</span>.<span class="bu">format</span>(<span class="bu">len</span>(word_list_1)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>There are 77505 cleaned words from all the negative reviews
There are 71279 cleaned words from all the positive reviews</code></pre>
</div>
</div>
<p>The distribution of words is a bit different because there might be some stopwords more frequent in the positive reviews that are non-existent in the negative reviews. However, this doesn’t really matter.</p>
<div class="cell" data-execution_count="13">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb18-1" aria-hidden="true" tabindex="-1"></a>sns.barplot(y<span class="op">=</span>fdist_0.index, x<span class="op">=</span>fdist_0.values, palette<span class="op">=</span>col)</span>
<span id="cb18-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb18-2" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Top 20 words in Negative reviews'</span>)</span>
<span id="cb18-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb18-3" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'count'</span>)</span>
<span id="cb18-4"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb18-4" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'word'</span>)</span>
<span id="cb18-5"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb18-5" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="./Report_files/cell-14-output-1.png" width="619" height="449"></p>
</div>
</div>
<p>Again, book, one, would comes up a lot. Surprisingly, good comes up on the bad reviews a lot.</p>
<p><strong>Positive reviews:</strong></p>
<div class="cell" data-execution_count="14">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb19-1" aria-hidden="true" tabindex="-1"></a>sns.barplot(y<span class="op">=</span>fdist_1.index, x<span class="op">=</span>fdist_1.values, palette<span class="op">=</span>col)</span>
<span id="cb19-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb19-2" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Top 20 words in Positive reviews'</span>)</span>
<span id="cb19-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb19-3" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'count'</span>)</span>
<span id="cb19-4"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb19-4" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'word'</span>)</span>
<span id="cb19-5"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb19-5" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="./Report_files/cell-15-output-1.png" width="609" height="449"></p>
</div>
</div>
<p>Now we see something different. The words ‘great’, ‘love’ comes up a lot while it doesn’t come up at all in the Negative reviews. This might be a good indicator on what constitutes as positive reviews and negative.</p>
<section id="bi-gram-frequency-distribution" class="level4">
<h4 class="anchored" data-anchor-id="bi-gram-frequency-distribution">Bi-gram Frequency Distribution<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#bi-gram-frequency-distribution" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h4>
<p>Instead of seeing what words occur more frequent, we can see what pairs of words occur most frequent. This will show more contextual information.</p>
<div class="cell" data-execution_count="15">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co">#convert bigram FreqDist to a panda Series</span></span>
<span id="cb20-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb20-2" aria-hidden="true" tabindex="-1"></a>fdist_bigram <span class="op">=</span> pd.Series(<span class="bu">dict</span>(FreqDist(<span class="bu">list</span>(nltk.bigrams(word_list_all))).most_common(<span class="dv">20</span>))).reset_index()</span>
<span id="cb20-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb20-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-4"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="co">#set index to a pair of words</span></span>
<span id="cb20-5"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb20-5" aria-hidden="true" tabindex="-1"></a>fdist_bigram <span class="op">=</span> fdist_bigram.set_index(fdist_bigram[<span class="st">'level_0'</span>] <span class="op">+</span> <span class="st">', '</span> <span class="op">+</span>fdist_bigram[<span class="st">'level_1'</span>])</span>
<span id="cb20-6"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb20-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-7"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb20-7" aria-hidden="true" tabindex="-1"></a><span class="co">#drop the unneeded columns</span></span>
<span id="cb20-8"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb20-8" aria-hidden="true" tabindex="-1"></a>fdist_bigram <span class="op">=</span> fdist_bigram.drop([<span class="st">'level_0'</span>,<span class="st">'level_1'</span>],axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb20-9"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb20-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-10"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb20-10" aria-hidden="true" tabindex="-1"></a>sns.barplot(y<span class="op">=</span>fdist_bigram.index, x<span class="op">=</span>fdist_bigram.loc[:,<span class="dv">0</span>].values, palette<span class="op">=</span>col)</span>
<span id="cb20-11"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb20-11" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Top 20 bigrams in all reviews'</span>)</span>
<span id="cb20-12"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb20-12" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'count'</span>)</span>
<span id="cb20-13"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb20-13" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'bigram'</span>)</span>
<span id="cb20-14"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb20-14" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="./Report_files/cell-16-output-1.png" width="697" height="449"></p>
</div>
</div>
<p>From this, we can see that (read, book) is most common. Interestingly, would,recommend is really common. Thus, I want to see what this looks like in the positive and negative reviews. This provides more contextual information.</p>
<p><strong>Negative Reviews</strong></p>
<div class="cell" data-execution_count="16">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co">#convert bigram FreqDist to a panda Series</span></span>
<span id="cb21-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb21-2" aria-hidden="true" tabindex="-1"></a>fdist_bigram_0 <span class="op">=</span> pd.Series(<span class="bu">dict</span>(FreqDist(<span class="bu">list</span>(nltk.bigrams(word_list_0))).most_common(<span class="dv">20</span>))).reset_index()</span>
<span id="cb21-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb21-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-4"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb21-4" aria-hidden="true" tabindex="-1"></a><span class="co">#set index to a pair of words</span></span>
<span id="cb21-5"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb21-5" aria-hidden="true" tabindex="-1"></a>fdist_bigram_0 <span class="op">=</span> fdist_bigram_0.set_index(fdist_bigram_0[<span class="st">'level_0'</span>] <span class="op">+</span> <span class="st">', '</span> <span class="op">+</span>fdist_bigram_0[<span class="st">'level_1'</span>])</span>
<span id="cb21-6"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb21-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-7"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb21-7" aria-hidden="true" tabindex="-1"></a><span class="co">#drop the unneeded columns</span></span>
<span id="cb21-8"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb21-8" aria-hidden="true" tabindex="-1"></a>fdist_bigram_0 <span class="op">=</span> fdist_bigram_0.drop([<span class="st">'level_0'</span>,<span class="st">'level_1'</span>],axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb21-9"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb21-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-10"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb21-10" aria-hidden="true" tabindex="-1"></a>sns.barplot(y<span class="op">=</span>fdist_bigram_0.index, x<span class="op">=</span>fdist_bigram_0.loc[:,<span class="dv">0</span>].values, palette<span class="op">=</span>col)</span>
<span id="cb21-11"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb21-11" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Top 20 bigrams in Negative reviews'</span>)</span>
<span id="cb21-12"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb21-12" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'count'</span>)</span>
<span id="cb21-13"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb21-13" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'bigram'</span>)</span>
<span id="cb21-14"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb21-14" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="./Report_files/cell-17-output-1.png" width="704" height="449"></p>
</div>
</div>
<p>Okay, this is quite funny. (Waste, Money) is the most common indicator. This is actually funny, and interesting. This shows that money is a big indicator for negative reviews.</p>
<p>Interestingly enough, (much, better) and (would, recommend) is also really high. My guess is that people would recommend something much better.</p>
<p><strong>Positive Reviews</strong></p>
<div class="cell" data-execution_count="17">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co">#convert bigram FreqDist to a panda Series</span></span>
<span id="cb22-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb22-2" aria-hidden="true" tabindex="-1"></a>fdist_bigram_1 <span class="op">=</span> pd.Series(<span class="bu">dict</span>(FreqDist(<span class="bu">list</span>(nltk.bigrams(word_list_1))).most_common(<span class="dv">20</span>))).reset_index()</span>
<span id="cb22-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb22-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-4"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="co">#set index to a pair of words</span></span>
<span id="cb22-5"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb22-5" aria-hidden="true" tabindex="-1"></a>fdist_bigram_1 <span class="op">=</span> fdist_bigram_1.set_index(fdist_bigram_1[<span class="st">'level_0'</span>] <span class="op">+</span> <span class="st">', '</span> <span class="op">+</span>fdist_bigram_1[<span class="st">'level_1'</span>])</span>
<span id="cb22-6"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb22-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-7"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb22-7" aria-hidden="true" tabindex="-1"></a><span class="co">#drop the unneeded columns</span></span>
<span id="cb22-8"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb22-8" aria-hidden="true" tabindex="-1"></a>fdist_bigram_1 <span class="op">=</span> fdist_bigram_1.drop([<span class="st">'level_0'</span>,<span class="st">'level_1'</span>],axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb22-9"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb22-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-10"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb22-10" aria-hidden="true" tabindex="-1"></a>sns.barplot(y<span class="op">=</span>fdist_bigram_1.index, x<span class="op">=</span>fdist_bigram_1.loc[:,<span class="dv">0</span>].values, palette<span class="op">=</span>col)</span>
<span id="cb22-11"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb22-11" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Top 20 bigrams in Positive reviews'</span>)</span>
<span id="cb22-12"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb22-12" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'count'</span>)</span>
<span id="cb22-13"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb22-13" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'bigram'</span>)</span>
<span id="cb22-14"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb22-14" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="./Report_files/cell-18-output-1.png" width="705" height="449"></p>
</div>
</div>
<p>(Highly, recommend) and (would, recommend) is really common in the positive reviews. This might mean that reviewers would say that they highly recommend the books in the positive reviews.</p>
<p>Though, (would, recommend) is quite common for both sentiment reviews. I believe this is because the phrase (would, recommend) can be used to recommend an alternative (negative reviews) and to recommend the current item (positive reviews). Thus, this showcases the importance of context in text. This will be used for future techniques for word processing called Word Embedding that we will explore later in the report.</p>
<p>I hope that by plotting bigrams frequency distributions that you can see how context of a word matters. In fact, you can also try plotting Trigrams frequency distributions, but I won’t plot it here.</p>
<p>Another EDA people like to do is Wordclouds:</p>
</section>
</section>
<section id="wordcloud" class="level2">
<h2 class="anchored" data-anchor-id="wordcloud">Wordcloud<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#wordcloud" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>
<p>Wordclouds are those cool looking images that see which words are most frequent words like the Frequency Distribution plots before but generally more visually appealing. Honestly, it doesn’t add more information or understanding to our data but it just looks cool. Let’s make a couple, few simple wordcloud and one funner wordlcloud.</p>
<section id="simple-wordcloud" class="level4">
<h4 class="anchored" data-anchor-id="simple-wordcloud">Simple Wordcloud:<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#simple-wordcloud" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h4>
<p>We will be using the WordCloud package for this.</p>
<p><strong>Wordcloud of one review:</strong></p>
<div class="cell" data-execution_count="18">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb23-1" aria-hidden="true" tabindex="-1"></a>review_one <span class="op">=</span> df_reduced[<span class="st">'content'</span>].iloc[<span class="dv">0</span>]</span>
<span id="cb23-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'The review that we are going to make as wordcloud is: </span><span class="ch">\n</span><span class="sc">{}</span><span class="st">'</span>.<span class="bu">format</span>(review_one))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>The review that we are going to make as wordcloud is: 
I bought this thinking it'd be sleek and decently useful. And, I bought this for my 15" MacBook Pro.But I regret my decision, to have bought this, without checking out at the local store.Problem is while the inner sides of the bag has small-baloon like cushion, the bottom of the bag just doesn't have anything. Its just one thin layer of neoprene.When the laptop is placed hard, it takes full beating.</code></pre>
</div>
</div>
<div class="cell" data-execution_count="19">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co">#make one wordcloud with the first review in our content</span></span>
<span id="cb25-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb25-2" aria-hidden="true" tabindex="-1"></a>one_review_wc <span class="op">=</span> WordCloud(background_color<span class="op">=</span><span class="st">"white"</span>).generate(review_one)</span>
<span id="cb25-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb25-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-4"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb25-4" aria-hidden="true" tabindex="-1"></a><span class="co">#plot it</span></span>
<span id="cb25-5"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb25-5" aria-hidden="true" tabindex="-1"></a>plt.imshow(one_review_wc,interpolation<span class="op">=</span><span class="st">'bilinear'</span>)</span>
<span id="cb25-6"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb25-6" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Wordcloud of a single review'</span>)</span>
<span id="cb25-7"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb25-7" aria-hidden="true" tabindex="-1"></a>plt.axis(<span class="st">"off"</span>)</span>
<span id="cb25-8"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb25-8" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="./Report_files/cell-20-output-1.png" width="540" height="300"></p>
</div>
</div>
<p>As you can see the wordcloud’s font size is affected by the frequency of the words. Now let’s try for the whole dataframe.</p>
<p><strong>Wordcloud of entire dataset:</strong></p>
<div class="cell" data-execution_count="20">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># get all the words from word_list_all into one long string seperated by whitespace</span></span>
<span id="cb26-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb26-2" aria-hidden="true" tabindex="-1"></a>text_all <span class="op">=</span> <span class="st">" "</span>.join(word <span class="cf">for</span> word <span class="kw">in</span> word_list_all)</span>
<span id="cb26-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb26-3" aria-hidden="true" tabindex="-1"></a>wordcloud_all <span class="op">=</span> WordCloud(background_color<span class="op">=</span><span class="st">"white"</span>).generate(text_all)</span>
<span id="cb26-4"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb26-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-5"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb26-5" aria-hidden="true" tabindex="-1"></a><span class="co">#plot it</span></span>
<span id="cb26-6"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb26-6" aria-hidden="true" tabindex="-1"></a>plt.imshow(wordcloud_all,interpolation<span class="op">=</span><span class="st">'bilinear'</span>)</span>
<span id="cb26-7"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb26-7" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Wordcloud of all reviews'</span>)</span>
<span id="cb26-8"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb26-8" aria-hidden="true" tabindex="-1"></a>plt.axis(<span class="st">"off"</span>)</span>
<span id="cb26-9"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb26-9" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="./Report_files/cell-21-output-1.png" width="540" height="300"></p>
</div>
</div>
<p>See it basically shows the same information as the frequency distribution.</p>
<p><strong>Wordcloud of negative dataset:</strong></p>
<div class="cell" data-execution_count="21">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># get all the words from word_list_all into one long string seperated by whitespace</span></span>
<span id="cb27-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb27-2" aria-hidden="true" tabindex="-1"></a>text_0 <span class="op">=</span> <span class="st">" "</span>.join(word <span class="cf">for</span> word <span class="kw">in</span> word_list_0)</span>
<span id="cb27-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb27-3" aria-hidden="true" tabindex="-1"></a>wordcloud_0 <span class="op">=</span> WordCloud(background_color<span class="op">=</span><span class="st">"white"</span>).generate(text_0)</span>
<span id="cb27-4"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb27-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-5"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb27-5" aria-hidden="true" tabindex="-1"></a><span class="co">#plot it</span></span>
<span id="cb27-6"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb27-6" aria-hidden="true" tabindex="-1"></a>plt.imshow(wordcloud_0,interpolation<span class="op">=</span><span class="st">'bilinear'</span>)</span>
<span id="cb27-7"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb27-7" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Wordcloud of negative reviews'</span>)</span>
<span id="cb27-8"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb27-8" aria-hidden="true" tabindex="-1"></a>plt.axis(<span class="st">"off"</span>)</span>
<span id="cb27-9"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb27-9" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="./Report_files/cell-22-output-1.png" width="540" height="300"></p>
</div>
</div>
<p>As you can see, it’s the same information as the frequency distribution before. Book is still the most common.</p>
<p><strong>Wordcloud of positive dataset:</strong></p>
<div class="cell" data-execution_count="22">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># get all the words from word_list_all into one long string seperated by whitespace</span></span>
<span id="cb28-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb28-2" aria-hidden="true" tabindex="-1"></a>text_1 <span class="op">=</span> <span class="st">" "</span>.join(word <span class="cf">for</span> word <span class="kw">in</span> word_list_1)</span>
<span id="cb28-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb28-3" aria-hidden="true" tabindex="-1"></a>wordcloud_1 <span class="op">=</span> WordCloud(background_color<span class="op">=</span><span class="st">"white"</span>).generate(text_1)</span>
<span id="cb28-4"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb28-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-5"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb28-5" aria-hidden="true" tabindex="-1"></a><span class="co">#plot it</span></span>
<span id="cb28-6"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb28-6" aria-hidden="true" tabindex="-1"></a>plt.imshow(wordcloud_1,interpolation<span class="op">=</span><span class="st">'bilinear'</span>)</span>
<span id="cb28-7"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb28-7" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Wordcloud of positive reviews'</span>)</span>
<span id="cb28-8"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb28-8" aria-hidden="true" tabindex="-1"></a>plt.axis(<span class="st">"off"</span>)</span>
<span id="cb28-9"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb28-9" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="./Report_files/cell-23-output-1.png" width="540" height="300"></p>
</div>
</div>
<p>As you can see, it’s the same information as the frequency distribution before. Great and good and love are still the most common.</p>
<p>Now we have seen what a simple WordCloud looks like, let’s make a fun one.</p>
<p><strong>Amazon Wordcloud:</strong></p>
<div class="cell" data-execution_count="23">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co">#I have done this code, so I'll load up the image directly to make it faster to render to HTML</span></span>
<span id="cb29-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="co">'''</span></span>
<span id="cb29-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb29-3" aria-hidden="true" tabindex="-1"></a><span class="co">#tutorial followed from datacamp: https://www.datacamp.com/tutorial/wordcloud-python</span></span>
<span id="cb29-4"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb29-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-5"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb29-5" aria-hidden="true" tabindex="-1"></a><span class="co">#load up the image as an array</span></span>
<span id="cb29-6"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb29-6" aria-hidden="true" tabindex="-1"></a><span class="co">amazon_mask = np.array(Image.open('figures/amazon_logo.png'))</span></span>
<span id="cb29-7"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb29-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-8"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb29-8" aria-hidden="true" tabindex="-1"></a><span class="co">#currently, all white pixels in amazon_mask is labelled as 0</span></span>
<span id="cb29-9"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb29-9" aria-hidden="true" tabindex="-1"></a><span class="co">#for wordcloud, we need it to be 255 not 0, </span></span>
<span id="cb29-10"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb29-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-11"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb29-11" aria-hidden="true" tabindex="-1"></a><span class="co">#transform function</span></span>
<span id="cb29-12"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb29-12" aria-hidden="true" tabindex="-1"></a><span class="co">def transform_format(val):</span></span>
<span id="cb29-13"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb29-13" aria-hidden="true" tabindex="-1"></a><span class="co">    if val == 0:</span></span>
<span id="cb29-14"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb29-14" aria-hidden="true" tabindex="-1"></a><span class="co">        return 255</span></span>
<span id="cb29-15"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb29-15" aria-hidden="true" tabindex="-1"></a><span class="co">    else:</span></span>
<span id="cb29-16"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb29-16" aria-hidden="true" tabindex="-1"></a><span class="co">        return val</span></span>
<span id="cb29-17"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb29-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-18"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb29-18" aria-hidden="true" tabindex="-1"></a><span class="co"># quite inefficient but it works</span></span>
<span id="cb29-19"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb29-19" aria-hidden="true" tabindex="-1"></a><span class="co">for i in range(len(amazon_mask)):</span></span>
<span id="cb29-20"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb29-20" aria-hidden="true" tabindex="-1"></a><span class="co">    for j in range(len(amazon_mask[i])):</span></span>
<span id="cb29-21"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb29-21" aria-hidden="true" tabindex="-1"></a><span class="co">        amazon_mask[i][j] = list(map(transform_format, amazon_mask[i][j]))</span></span>
<span id="cb29-22"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb29-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-23"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb29-23" aria-hidden="true" tabindex="-1"></a><span class="co">wordcloud_amazon = WordCloud(background_color="white", max_words=1000, mask=amazon_mask,contour_width=2, contour_color='black').generate(text_all)</span></span>
<span id="cb29-24"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb29-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-25"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb29-25" aria-hidden="true" tabindex="-1"></a><span class="co"># create coloring from image</span></span>
<span id="cb29-26"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb29-26" aria-hidden="true" tabindex="-1"></a><span class="co">amazon_colors = ImageColorGenerator(amazon_mask)</span></span>
<span id="cb29-27"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb29-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-28"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb29-28" aria-hidden="true" tabindex="-1"></a><span class="co">#plot it</span></span>
<span id="cb29-29"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb29-29" aria-hidden="true" tabindex="-1"></a><span class="co">fig = plt.figure(figsize=[7,7])</span></span>
<span id="cb29-30"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb29-30" aria-hidden="true" tabindex="-1"></a><span class="co">plt.imshow(wordcloud_amazon.recolor(color_func=amazon_colors), interpolation="bilinear")</span></span>
<span id="cb29-31"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb29-31" aria-hidden="true" tabindex="-1"></a><span class="co">plt.axis("off")</span></span>
<span id="cb29-32"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb29-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-33"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb29-33" aria-hidden="true" tabindex="-1"></a><span class="co">#save the figure into a file</span></span>
<span id="cb29-34"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb29-34" aria-hidden="true" tabindex="-1"></a><span class="co">plt.savefig("figures/wordcloud/amazon_wc.png", format="png")</span></span>
<span id="cb29-35"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb29-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-36"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb29-36" aria-hidden="true" tabindex="-1"></a><span class="co">#save the image object as a pickle file</span></span>
<span id="cb29-37"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb29-37" aria-hidden="true" tabindex="-1"></a><span class="co">with open('figures/pickle_data/amazon_wordcloud.pickle', 'wb') as f:</span></span>
<span id="cb29-38"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb29-38" aria-hidden="true" tabindex="-1"></a><span class="co">    pickle.dump(fig, f)</span></span>
<span id="cb29-39"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb29-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-40"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb29-40" aria-hidden="true" tabindex="-1"></a><span class="co">'''</span></span>
<span id="cb29-41"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb29-41" aria-hidden="true" tabindex="-1"></a><span class="co">#load the image object as a pickle file</span></span>
<span id="cb29-42"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb29-42" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(<span class="st">'figures/pickle_data/amazon_wordcloud.pickle'</span>, <span class="st">'rb'</span>) <span class="im">as</span> f:</span>
<span id="cb29-43"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb29-43" aria-hidden="true" tabindex="-1"></a>    fig <span class="op">=</span> pickle.load(f)</span>
<span id="cb29-44"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb29-44" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="./Report_files/cell-24-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>It looks good! Though, the color of the smile is off, but it’s fine. Our code works!</p>
<p>There will be more graphs later, but for now, let’s move on to my favorite part: Word Embedding!</p>
<p>But before that, we have to train and test split.</p>
</section>
</section>
</section>
<section id="train-and-test-split" class="level1">
<h1>Train and Test split</h1>
<p>We are splitting the train and test split right now to avoid any data leakage when we eventually get to our word embeddings part. I don’t want the BoW, TFDIF, Word2Vec model to learn from the testing set, which it will do if I don’t split now. So let’s split our data.</p>
<div class="cell" data-execution_count="24">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb30-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df_reduced[<span class="st">'content'</span>]</span>
<span id="cb30-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb30-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df_reduced[<span class="st">'label'</span>]</span>
<span id="cb30-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb30-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-4"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb30-4" aria-hidden="true" tabindex="-1"></a><span class="co">#split to train and test set with stratifying on the label</span></span>
<span id="cb30-5"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb30-5" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb30-6"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb30-6" aria-hidden="true" tabindex="-1"></a>    X, y, test_size<span class="op">=</span><span class="fl">0.33</span>, random_state<span class="op">=</span>seed, stratify<span class="op">=</span>y)</span>
<span id="cb30-7"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb30-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-8"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb30-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'The shape of X_train:'</span>, X_train.shape)</span>
<span id="cb30-9"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb30-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'The shape of y_train:'</span>, y_train.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>The shape of X_train: (2680,)
The shape of y_train: (2680,)</code></pre>
</div>
</div>
<p>To check the distribution of labels in our training and testing set, let’s check it right now.</p>
<div class="cell" data-execution_count="25">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb32-1" aria-hidden="true" tabindex="-1"></a>sns.barplot(x<span class="op">=</span>y_train.value_counts().index, y<span class="op">=</span>y_train.value_counts().values, palette<span class="op">=</span>col)</span>
<span id="cb32-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb32-2" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Distribution of label in training set'</span>)</span>
<span id="cb32-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb32-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-4"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb32-4" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="./Report_files/cell-26-output-1.png" width="583" height="431"></p>
</div>
</div>
<div class="cell" data-execution_count="26">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb33-1" aria-hidden="true" tabindex="-1"></a>sns.barplot(x<span class="op">=</span>y_test.value_counts().index, y<span class="op">=</span>y_test.value_counts().values, palette<span class="op">=</span>col)</span>
<span id="cb33-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb33-2" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Distribution of label in testing set'</span>)</span>
<span id="cb33-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb33-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-4"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb33-4" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="./Report_files/cell-27-output-1.png" width="575" height="431"></p>
</div>
</div>
<p>Great! Our labels are distributed evenly! Now let’s move onto my favorite part: Text Embedding!</p>
</section>
<section id="feature-extraction" class="level1">
<h1>Feature Extraction</h1>
<p>Before feeding the text to the model, we have to extract some features or information from the text. To do this, we transform the text into certain quantifiable data that captures semantic, contextual, or/and other information regarding the data.</p>
<section id="word-embedding" class="level2">
<h2 class="anchored" data-anchor-id="word-embedding">Word Embedding<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#word-embedding" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>
<p>Word embedding captures important information about a sentence or text and quantifies it to numerical values to be fed into the model. In fact, word embedding plays a important role in a model’s performance. Without word embedding, we can’t really feed the text into the model and give semantic/contextual information to the model.</p>
<p><strong>Types of Word Embedding</strong>: 1. <strong>Bag of Words</strong> 2. <strong>TF-IDF</strong> 3. <strong>Word2Vec</strong> 4. gloVe 5. BERT</p>
<p>For this project we will use BoW, TF-IDF, and Word2Vec. Then we will compare each method and see respective model’s performances. For BoW and TF-IDF, we will use sci-kitlearn and for Word2Vec we will use the gensim package.</p>
<section id="bag-of-words-count-vectorizer" class="level3">
<h3 class="anchored" data-anchor-id="bag-of-words-count-vectorizer">Bag of Words (count vectorizer)<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#bag-of-words-count-vectorizer" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h3>
<p>Bag of words embedding is the most rudimentary and simplest word embedding technique! It simply counts how many times each word and assigns the word’s count to the word. Thus, it’s also called count vectorizer! For example: “Apples are apples” = {‘Apples’: 2, ‘are’: 1}.</p>
<p>Now let’s apply it to the data!</p>
<div class="cell" data-execution_count="27">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co">'''</span></span>
<span id="cb34-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb34-2" aria-hidden="true" tabindex="-1"></a><span class="co">#use our pre-processing function as the tokenizer: this acts as a recipe</span></span>
<span id="cb34-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb34-3" aria-hidden="true" tabindex="-1"></a><span class="co">#create an instance of the countvectorizer</span></span>
<span id="cb34-4"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb34-4" aria-hidden="true" tabindex="-1"></a><span class="co">cv = CountVectorizer(tokenizer=preprocess_text) </span></span>
<span id="cb34-5"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb34-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-6"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb34-6" aria-hidden="true" tabindex="-1"></a><span class="co">#fit our data to the vectorizer</span></span>
<span id="cb34-7"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb34-7" aria-hidden="true" tabindex="-1"></a><span class="co">cv.fit(X_train)</span></span>
<span id="cb34-8"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb34-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-9"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb34-9" aria-hidden="true" tabindex="-1"></a><span class="co">#save our fitted model</span></span>
<span id="cb34-10"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb34-10" aria-hidden="true" tabindex="-1"></a><span class="co">with open('models/cv.pickle', 'wb') as f:</span></span>
<span id="cb34-11"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb34-11" aria-hidden="true" tabindex="-1"></a><span class="co">    pickle.dump(cv, f)</span></span>
<span id="cb34-12"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb34-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-13"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb34-13" aria-hidden="true" tabindex="-1"></a><span class="co">'''</span></span>
<span id="cb34-14"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb34-14" aria-hidden="true" tabindex="-1"></a><span class="co">#load our fitted model</span></span>
<span id="cb34-15"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb34-15" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(<span class="st">'models/cv.pickle'</span>, <span class="st">'rb'</span>) <span class="im">as</span> f:</span>
<span id="cb34-16"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb34-16" aria-hidden="true" tabindex="-1"></a>    cv <span class="op">=</span> pickle.load(f)</span>
<span id="cb34-17"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb34-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-18"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb34-18" aria-hidden="true" tabindex="-1"></a><span class="co">#transform our training set to the countvectorizer</span></span>
<span id="cb34-19"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb34-19" aria-hidden="true" tabindex="-1"></a>X_train_bow <span class="op">=</span> cv.transform(X_train)</span>
<span id="cb34-20"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb34-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-21"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb34-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'The shape of the Bag of Words transformed training set is: </span><span class="sc">{}</span><span class="st">'</span>.<span class="bu">format</span>(X_train_bow.shape))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>The shape of the Bag of Words transformed training set is: (2680, 14446)</code></pre>
</div>
</div>
<p>We will have to do this to the testing set later, so let’s make a custom function to make it easier to do it later.</p>
<p>The first five in the vocabulary list:</p>
<div class="cell" data-execution_count="28">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb36-1" aria-hidden="true" tabindex="-1"></a>pd.Series(<span class="bu">list</span>(cv.vocabulary_.items())[<span class="dv">0</span>:<span class="dv">5</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="28">
<pre><code>0       (used, 13639)
1     (product, 9858)
2         (day, 3095)
3          (ago, 294)
4    (stopped, 12242)
dtype: object</code></pre>
</div>
</div>
<p>We can see that it’s basically, the word and its respective counts.</p>
<p>As you can see above, it creates a vocab list and its respective frequency. <strong>Pros</strong>: 1. Computationally fast 2. Easy to interpret</p>
<p><strong>Cons</strong>: 1. Not flexible to new data as vocab list increases 2. Doesn’t contain any information on order of words and or grammar of sentences</p>
<p>TF-IDF helps with alleviating BoW problems by providing a bit more contextual information. Now let’s try TF-IDF!</p>
</section>
<section id="tf-idf-term-frequency---inverse-document-frequency" class="level3">
<h3 class="anchored" data-anchor-id="tf-idf-term-frequency---inverse-document-frequency">TF-IDF (Term Frequency - Inverse Document Frequency)<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#tf-idf-term-frequency---inverse-document-frequency" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h3>
<p>The TF-IDF method assigns a score (the TF-IDF score) which gives more importance to rarer words in the text relative to how often it appears in the entire corpus (the entire dataset in this case). This helps give more importance to rarer words like <strong>technical jargon</strong>, and less importance to common words like <strong>and, then, would</strong>.</p>
<p>The method achieves this by how it calculates:</p>
<p><strong>Term Frequency:</strong> <span class="math display"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" display="true" tabindex="0" ctxtmenu_counter="0" style="font-size: 113.1%; position: relative;"><mjx-math display="true" class="MJX-TEX" aria-hidden="true" style="margin-left: 0px; margin-right: 0px;"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D447 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D439 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mfrac space="4"><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mtext class="mjx-n"><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c75"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c62"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c66"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c73"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c68"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c70"></mjx-c><mjx-c class="mjx-c70"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c73"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c68"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c64"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c75"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c74"></mjx-c></mjx-mtext></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mtext class="mjx-n"><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c75"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c62"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c66"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c77"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c64"></mjx-c><mjx-c class="mjx-c73"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c68"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c64"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c75"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c74"></mjx-c></mjx-mtext></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac></mjx-math><mjx-assistive-mml unselectable="on" display="block"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mi>T</mi><mi>F</mi><mo>=</mo><mfrac><mtext>number of times the term appears in the document</mtext><mtext>total number of words in the document</mtext></mfrac></math></mjx-assistive-mml></mjx-container></span></p>
<p><strong>Inverse Document Frequency :</strong> <span class="math display"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" display="true" tabindex="0" ctxtmenu_counter="1" style="font-size: 113.1%; position: relative;"><mjx-math display="true" class="MJX-TEX" aria-hidden="true" style="margin-left: 0px; margin-right: 0px;"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43C TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D437 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D439 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mfrac space="4"><mjx-frac type="d"><mjx-num><mjx-nstrut type="d"></mjx-nstrut><mjx-mtext class="mjx-n"><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c75"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c62"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c66"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c64"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c75"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c73"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c68"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c70"></mjx-c><mjx-c class="mjx-c75"></mjx-c><mjx-c class="mjx-c73"></mjx-c></mjx-mtext></mjx-num><mjx-dbox><mjx-dtable><mjx-line type="d"></mjx-line><mjx-row><mjx-den><mjx-dstrut type="d"></mjx-dstrut><mjx-mtext class="mjx-n"><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c75"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c62"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c66"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c64"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c75"></mjx-c><mjx-c class="mjx-c6D"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c73"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c68"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c70"></mjx-c><mjx-c class="mjx-c75"></mjx-c><mjx-c class="mjx-c73"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c68"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c63"></mjx-c><mjx-c class="mjx-c6F"></mjx-c><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c68"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c6D"></mjx-c></mjx-mtext></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac></mjx-math><mjx-assistive-mml unselectable="on" display="block"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mi>I</mi><mi>D</mi><mi>F</mi><mo>=</mo><mfrac><mtext>number of documents in the corpus</mtext><mtext>number of documents in the corpus that contain the term</mtext></mfrac></math></mjx-assistive-mml></mjx-container></span></p>
<p><strong>Term Frequency - Inverse Document Frequency:</strong> <span class="math display"><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" display="true" tabindex="0" ctxtmenu_counter="2" style="font-size: 113.1%; position: relative;"><mjx-math display="true" class="MJX-TEX" aria-hidden="true" style="margin-left: 0px; margin-right: 0px;"><mjx-mtext class="mjx-n"><mjx-c class="mjx-c54"></mjx-c><mjx-c class="mjx-c46"></mjx-c><mjx-c class="mjx-c2D"></mjx-c><mjx-c class="mjx-c49"></mjx-c><mjx-c class="mjx-c44"></mjx-c><mjx-c class="mjx-c46"></mjx-c></mjx-mtext><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mtext class="mjx-n" space="4"><mjx-c class="mjx-c54"></mjx-c><mjx-c class="mjx-c46"></mjx-c></mjx-mtext><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2217"></mjx-c></mjx-mo><mjx-mtext class="mjx-n" space="3"><mjx-c class="mjx-c49"></mjx-c><mjx-c class="mjx-c44"></mjx-c><mjx-c class="mjx-c46"></mjx-c></mjx-mtext></mjx-math><mjx-assistive-mml unselectable="on" display="block"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtext>TF-IDF</mtext><mo>=</mo><mtext>TF</mtext><mo>∗</mo><mtext>IDF</mtext></math></mjx-assistive-mml></mjx-container></span></p>
<p>While Term frequency calculates how often a word appears in the document, the Inverse document frequency calculcates the rarity of the word. This gives a more nuanced score to each term instead of just counting.</p>
<blockquote class="blockquote">
<p>Formula pulled from https://www.learndatasci.com/glossary/tf-idf-term-frequency-inverse-document-frequency/</p>
</blockquote>
<p>Now let’s apply it using sci-kit-learn!</p>
<div class="cell" data-execution_count="29">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="co">'''</span></span>
<span id="cb38-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb38-2" aria-hidden="true" tabindex="-1"></a><span class="co">#use our function as the recipe and create an instance of tfdif</span></span>
<span id="cb38-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb38-3" aria-hidden="true" tabindex="-1"></a><span class="co">tfidf = TfidfVectorizer(tokenizer=preprocess_text)</span></span>
<span id="cb38-4"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb38-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-5"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb38-5" aria-hidden="true" tabindex="-1"></a><span class="co">#fit our data to the vectorizer</span></span>
<span id="cb38-6"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb38-6" aria-hidden="true" tabindex="-1"></a><span class="co">tfidf.fit(X_train)</span></span>
<span id="cb38-7"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb38-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-8"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb38-8" aria-hidden="true" tabindex="-1"></a><span class="co">#save our fitted model</span></span>
<span id="cb38-9"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb38-9" aria-hidden="true" tabindex="-1"></a><span class="co">with open('models/tfidf.pickle', 'wb') as f:</span></span>
<span id="cb38-10"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb38-10" aria-hidden="true" tabindex="-1"></a><span class="co">    pickle.dump(tfidf, f)</span></span>
<span id="cb38-11"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb38-11" aria-hidden="true" tabindex="-1"></a><span class="co">'''</span></span>
<span id="cb38-12"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb38-12" aria-hidden="true" tabindex="-1"></a><span class="co">#load our fitted model</span></span>
<span id="cb38-13"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb38-13" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(<span class="st">'models/tfidf.pickle'</span>, <span class="st">'rb'</span>) <span class="im">as</span> f:</span>
<span id="cb38-14"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb38-14" aria-hidden="true" tabindex="-1"></a>    tfidf <span class="op">=</span> pickle.load(f)</span>
<span id="cb38-15"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb38-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-16"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb38-16" aria-hidden="true" tabindex="-1"></a><span class="co">#transform it</span></span>
<span id="cb38-17"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb38-17" aria-hidden="true" tabindex="-1"></a>X_train_tfidf <span class="op">=</span> tfidf.fit_transform(X_train)</span>
<span id="cb38-18"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb38-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-19"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb38-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'The shape of the TF-IDF transformed training set is: </span><span class="sc">{}</span><span class="st">'</span>.<span class="bu">format</span>(X_train_tfidf.shape))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>The shape of the TF-IDF transformed training set is: (2680, 14446)</code></pre>
</div>
</div>
<p>We succeeded it’s the same shape as countVectorizer.</p>
<p>Now let’s try Word2Vec.</p>
</section>
<section id="word2vec" class="level3">
<h3 class="anchored" data-anchor-id="word2vec">Word2Vec<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#word2vec" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h3>
<p>Word2Vec was developed by Tomas Mikolov and other researchers at Google in 2013. Instead of calculating term frequency, it uses a neural network that takes a word and its surrounding words in the corpus, and compute a cosine-sine similarity score with the word and its surrounding words. To my understanding, all it is doing computing a score to each word that quantifies how similar one word is to another word, and it does this by looking at what words a word is usually with, what position the word is at in the sentence, and other things. <br></p>
<p>From this, words that have similar scores will be semantically similar while words that have different scores are semantically different. This tries to captures the semantic and contextual information of a word.</p>
<p><strong>Architecture</strong></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="file:///C:/Users/neals/Documents/GitHub/sent_amazon/figures/fig1_word2vec_archi.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure 1: Word2Vec Architecture</figcaption><p></p>
</figure>
</div>
<p>Word2Vec is essentially a 2 layer neural network.</p>
<p>There are two varieties of Word2Vec: CBoW (continous bag of words) and Skip-gram. CBoW and Skip-gram are essentially opposites.</p>
<p>CBoW takes a word’s adjacent words as inputs and uses this to predict the current word, while Skip-gram takes the current word as input and predicts its surrounding. Though both are achieving the same thing, CBoW is generally faster and makes better representations of a word, while skip-gram is able to represent rarer words better.</p>
<p>Now let’s apply to our data! We will use the gensim package for this. &gt; Image from the Google published document on Word2Vec: https://arxiv.org/pdf/1301.3781.pdf</p>
<div class="cell" data-execution_count="30">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="co">#let's pre-process our data first as the package won't process it first for us</span></span>
<span id="cb40-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb40-2" aria-hidden="true" tabindex="-1"></a>X_train_clean <span class="op">=</span> X_train.<span class="bu">apply</span>(<span class="kw">lambda</span> x: preprocess_text(x))</span>
<span id="cb40-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb40-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-4"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb40-4" aria-hidden="true" tabindex="-1"></a><span class="co">'''</span></span>
<span id="cb40-5"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb40-5" aria-hidden="true" tabindex="-1"></a><span class="co">Let's create an instance of the Word2Vec model on our clean X_train.</span></span>
<span id="cb40-6"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb40-6" aria-hidden="true" tabindex="-1"></a><span class="co">The parameter min_count specifies how frequent a word must be to be used to train the model.</span></span>
<span id="cb40-7"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb40-7" aria-hidden="true" tabindex="-1"></a><span class="co">'''</span></span>
<span id="cb40-8"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb40-8" aria-hidden="true" tabindex="-1"></a>wv_mod <span class="op">=</span> word2vec.Word2Vec(X_train_clean, min_count<span class="op">=</span><span class="dv">25</span>,vector_size<span class="op">=</span><span class="dv">200</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Now we created a vector of size 200 for every word. Let’s see what it looks like for the word ‘book’:</p>
<div class="cell" data-execution_count="31">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb41-1" aria-hidden="true" tabindex="-1"></a>wv_mod.wv[<span class="st">'book'</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="31">
<pre><code>array([-0.00347652, -0.01369283, -0.02323131,  0.16152853,  0.26885512,
       -0.23731893, -0.00634219,  0.31662107, -0.08801959,  0.17058177,
       -0.10241105, -0.08138572, -0.00160578,  0.21233514, -0.11053728,
       -0.10872643, -0.02481394,  0.06290041, -0.002296  , -0.28494427,
        0.07371146, -0.12900388, -0.09762742, -0.02675324,  0.06153736,
       -0.13002189, -0.12939504, -0.24296962, -0.12034591,  0.17794068,
        0.1888227 ,  0.02645311,  0.03535416, -0.01859169,  0.01804625,
        0.13685489,  0.20700012, -0.08307316, -0.09197203, -0.24446012,
       -0.2508958 ,  0.03708582,  0.0362338 ,  0.08124904,  0.26955506,
       -0.02458439, -0.04767902, -0.02030738,  0.11905677,  0.18054251,
        0.10548911, -0.04801574, -0.08548512, -0.1279816 ,  0.01553229,
       -0.05843317,  0.13506438, -0.131945  , -0.1694277 , -0.00575754,
       -0.04385435,  0.01969573, -0.09145524, -0.06215758, -0.27818698,
       -0.03491876, -0.00189365,  0.34634453, -0.10781386,  0.1494449 ,
        0.03631331,  0.00840454,  0.24255347,  0.00163746,  0.05867527,
        0.04298714,  0.17140254, -0.17588769, -0.28792572, -0.05124796,
       -0.05028227, -0.06426845, -0.13659115,  0.33760828, -0.05074554,
       -0.04200074, -0.08157616,  0.23701446,  0.02175615,  0.04698156,
        0.09968622,  0.27845797,  0.01176822,  0.15304798,  0.31570393,
        0.23628984,  0.05554347, -0.10941512,  0.18778645,  0.00943196,
       -0.22616988,  0.33198074,  0.07661788, -0.05207649, -0.20770599,
       -0.17032903,  0.10980845,  0.15755747, -0.04719457, -0.12556198,
       -0.01095824, -0.16883186, -0.11635742, -0.15297897,  0.03771335,
        0.01605069,  0.10162101, -0.31377274, -0.00082973, -0.16094504,
        0.02208149,  0.28053302,  0.11740399, -0.14658111, -0.11004975,
        0.10806183, -0.19322634, -0.08176406, -0.05906858, -0.09309019,
        0.1403056 ,  0.02592672,  0.01919251, -0.06697018, -0.09291761,
        0.24896725, -0.13667993, -0.31622437, -0.12733825, -0.29502067,
        0.08090263, -0.22345054, -0.0918979 , -0.19639993, -0.14393161,
       -0.18700156, -0.06822469, -0.00290859, -0.07929442,  0.08186042,
        0.06948206, -0.20926124, -0.03574505,  0.18874367, -0.2523746 ,
        0.31705397,  0.15797786,  0.10589889, -0.1488009 ,  0.10497339,
        0.11140178,  0.0971325 , -0.07789701, -0.04780465, -0.19895796,
        0.07713517,  0.06099315, -0.1629743 , -0.06626189,  0.02962861,
       -0.20811805,  0.03294994,  0.08357091, -0.1222264 ,  0.08555754,
        0.16691744, -0.14525025,  0.05044271,  0.08635011,  0.08321233,
        0.04561447,  0.0133754 ,  0.03517395,  0.15487964,  0.22448272,
        0.08768584, -0.12184352,  0.1426835 ,  0.27792323,  0.0554179 ,
        0.16785891, -0.07403175, -0.07059517, -0.08396782,  0.16801667,
        0.1010591 ,  0.10294348, -0.12583312, -0.03423617, -0.0990693 ],
      dtype=float32)</code></pre>
</div>
</div>
<p>As you can see, the word book is assigned a vector space with 200 dimensions.</p>
<p>What does this mean? To explain further, I will vizualize the data. I learned a dimension reduction technique before called t-SNE. t-SNE is a dimension reduction technique for vizualizing high dimension data by mapping each datapoint in the high dimensional space into a 2-dimensional space!</p>
</section>
<section id="more-vizualizations-t-sne-t-distributed-stochastic-neighbor-embedding" class="level3">
<h3 class="anchored" data-anchor-id="more-vizualizations-t-sne-t-distributed-stochastic-neighbor-embedding">More Vizualizations: t-SNE (t-distributed Stochastic Neighbor Embedding)<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#more-vizualizations-t-sne-t-distributed-stochastic-neighbor-embedding" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h3>
<p>I won’t go into detail but t-SNE works by calculating the conditional probability that one datapoint will be a neighbor with another datapoint by producing a Gaussian probability distribution with variance calculated by a value called perplexity. Then, it scatters these datapoints into a 2 or 3 dimensional space and creates a t-student distribution on each of the datapoint. Next, using gradient descent, it minimzes the difference between the gaussian and t-student probability distribution by minimizing a metric called Kullback-Leiber divergence. Doing this, every datapoint will be mapped into a lower dimensional space.</p>
<blockquote class="blockquote">
<p>You can read the original paper or a medium article on the topic:</p>
<blockquote class="blockquote">
<p>https://jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf</p>
<p>https://towardsdatascience.com/an-introduction-to-t-sne-with-python-example-5a3a293108d1</p>
</blockquote>
</blockquote>
<p>Now let’s try it!</p>
<div class="cell" data-execution_count="32">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="co">#let's create a list of unique words</span></span>
<span id="cb43-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb43-2" aria-hidden="true" tabindex="-1"></a>words_list <span class="op">=</span> wv_mod.wv.index_to_key</span>
<span id="cb43-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb43-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-4"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb43-4" aria-hidden="true" tabindex="-1"></a><span class="co">#get each word vectors into a list</span></span>
<span id="cb43-5"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb43-5" aria-hidden="true" tabindex="-1"></a>word_vectors <span class="op">=</span> []</span>
<span id="cb43-6"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb43-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-7"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb43-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> word <span class="kw">in</span> words_list:</span>
<span id="cb43-8"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb43-8" aria-hidden="true" tabindex="-1"></a>    word_vectors.append(wv_mod.wv[word])</span>
<span id="cb43-9"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb43-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb43-10"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb43-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'The word is: </span><span class="sc">{}</span><span class="st">.'</span>.<span class="bu">format</span>(words_list[<span class="dv">5</span>]))</span>
<span id="cb43-11"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb43-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'And its respective word vector is: </span><span class="ch">\n</span><span class="sc">{}</span><span class="st">'</span>.<span class="bu">format</span>(word_vectors[<span class="dv">5</span>]))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>The word is: time.
And its respective word vector is: 
[-0.00492706 -0.01365485 -0.02535967  0.13548587  0.26867008 -0.24175468
 -0.0187937   0.31054458 -0.07357496  0.16536714 -0.10458431 -0.08331867
  0.01317494  0.20180316 -0.10064452 -0.10290216 -0.03423164  0.05247393
  0.00358909 -0.28258842  0.06792756 -0.13846417 -0.10364445 -0.02868529
  0.04005826 -0.11763566 -0.13133813 -0.24443978 -0.10844587  0.18425232
  0.1926821   0.02079395  0.03477968 -0.00789148  0.01768583  0.14135239
  0.19270675 -0.07527673 -0.09987144 -0.23563388 -0.24540126  0.02346798
  0.02787978  0.08711877  0.2600609  -0.03114848 -0.0363961  -0.03686654
  0.10403955  0.17042415  0.11193623 -0.04680677 -0.08755349 -0.13356258
  0.01166634 -0.05097801  0.12513612 -0.13344887 -0.16413677 -0.00993094
 -0.04478468  0.00956145 -0.08850256 -0.05507041 -0.2757249  -0.01908737
 -0.0097589   0.33657238 -0.10778194  0.15140955  0.03082948  0.00477293
  0.24727483  0.01063995  0.05430534  0.04763627  0.1770481  -0.1853429
 -0.28431746 -0.04266747 -0.05107531 -0.0608013  -0.1425894   0.33680153
 -0.04606169 -0.04349995 -0.08378218  0.24125925  0.03581043  0.04448127
  0.09372634  0.2729985   0.01820794  0.155928    0.302862    0.23326476
  0.07159177 -0.10396107  0.17727993  0.01204774 -0.20842347  0.32762432
  0.07930159 -0.06137618 -0.2154582  -0.1748408   0.1081574   0.16232607
 -0.03488184 -0.12766655 -0.00913923 -0.15881029 -0.11664374 -0.16305542
  0.04345167 -0.00136503  0.09891723 -0.32325214 -0.00268215 -0.1663842
  0.02164297  0.28147286  0.10844598 -0.13933413 -0.11249429  0.10031414
 -0.19290061 -0.07879997 -0.06467904 -0.10699723  0.12466231  0.02648204
  0.0207316  -0.06316885 -0.09020264  0.24655649 -0.14575589 -0.31732035
 -0.1347852  -0.3115761   0.06244562 -0.2117232  -0.08289065 -0.18617435
 -0.14128792 -0.19074447 -0.06813541 -0.00400328 -0.08230651  0.08616357
  0.06136663 -0.20829709 -0.02878198  0.19508344 -0.25282013  0.309836
  0.15554762  0.11304656 -0.1453478   0.10149896  0.11740942  0.10368989
 -0.0672618  -0.0360401  -0.21237954  0.07750566  0.05658068 -0.15760513
 -0.07194555  0.02364752 -0.2044703   0.04824916  0.08135276 -0.13201681
  0.09410283  0.17658626 -0.13538879  0.05592202  0.08091214  0.09038115
  0.05449712  0.02282027  0.02558755  0.15266138  0.2317791   0.08377996
 -0.12825504  0.16183081  0.28445816  0.06643192  0.16987081 -0.07520512
 -0.07677393 -0.08248997  0.16810797  0.10120009  0.09731961 -0.12578516
 -0.03052975 -0.10875724]</code></pre>
</div>
</div>
<p>We can see what the word ‘time’ and its respective word vector.</p>
<p>Let’s apply t-SNE to our word2vec word vectors and map it to a 2 dimensional space!</p>
<div class="cell" data-execution_count="33">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="co">#create an instance of T-SNE</span></span>
<span id="cb45-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb45-2" aria-hidden="true" tabindex="-1"></a><span class="co"># n_components is the dimensions of the lower dimension space</span></span>
<span id="cb45-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb45-3" aria-hidden="true" tabindex="-1"></a><span class="co"># perplexity is proportionally how many neighbors one datapoint will have</span></span>
<span id="cb45-4"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb45-4" aria-hidden="true" tabindex="-1"></a>tsne_mod <span class="op">=</span> TSNE(n_components<span class="op">=</span><span class="dv">2</span>, perplexity<span class="op">=</span><span class="dv">40</span>, n_iter<span class="op">=</span><span class="dv">1000</span>,init<span class="op">=</span><span class="st">'random'</span>,learning_rate<span class="op">=</span><span class="dv">200</span>,random_state<span class="op">=</span>seed)</span>
<span id="cb45-5"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb45-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-6"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb45-6" aria-hidden="true" tabindex="-1"></a><span class="co">#fit and transform tsne on every word vector</span></span>
<span id="cb45-7"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb45-7" aria-hidden="true" tabindex="-1"></a>wv_mod_tsne <span class="op">=</span> tsne_mod.fit_transform(word_vectors)</span>
<span id="cb45-8"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb45-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-9"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb45-9" aria-hidden="true" tabindex="-1"></a><span class="co"># make the dataframe consisting of the word, and its respective tsne x and y values</span></span>
<span id="cb45-10"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb45-10" aria-hidden="true" tabindex="-1"></a>tsne_df <span class="op">=</span> pd.DataFrame(<span class="bu">list</span>(<span class="bu">zip</span>(words_list,wv_mod_tsne[:,<span class="dv">0</span>],wv_mod_tsne[:,<span class="dv">1</span>])), </span>
<span id="cb45-11"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb45-11" aria-hidden="true" tabindex="-1"></a>                       columns<span class="op">=</span>[<span class="st">'word'</span>,<span class="st">'tsne_x'</span>,<span class="st">'tsne_y'</span>])</span>
<span id="cb45-12"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb45-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tsne_df.head())</span>
<span id="cb45-13"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb45-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-14"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb45-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'The shape of the t-SNE dataframe is: </span><span class="sc">{}</span><span class="st">'</span>.<span class="bu">format</span>(tsne_df.shape))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>    word     tsne_x     tsne_y
0   book -12.925924  11.967720
1    one -15.378646   4.284742
2   like -14.341532   8.487006
3   good -14.272281   2.986966
4  would -19.055538   8.123889
The shape of the t-SNE dataframe is: (727, 3)</code></pre>
</div>
</div>
<p>As you can see, with t-SNE we can get x and y coordinates for each word. Now let’s plot it!</p>
<div class="cell" data-execution_count="34">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="co"># I have ran it before, and it will take a while</span></span>
<span id="cb47-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb47-2" aria-hidden="true" tabindex="-1"></a><span class="co">'''</span></span>
<span id="cb47-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb47-3" aria-hidden="true" tabindex="-1"></a><span class="co">#plotting code from https://www.kaggle.com/code/jeffd23/visualizing-word-vectors-with-t-sne/notebook</span></span>
<span id="cb47-4"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb47-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-5"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb47-5" aria-hidden="true" tabindex="-1"></a><span class="co">fig = plt.figure(figsize=(16, 16))</span></span>
<span id="cb47-6"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb47-6" aria-hidden="true" tabindex="-1"></a><span class="co">for i in range(len(tsne_df['word'])):</span></span>
<span id="cb47-7"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb47-7" aria-hidden="true" tabindex="-1"></a><span class="co">    plt.scatter(x=tsne_df['tsne_x'][i],y=tsne_df['tsne_y'][i], alpha=1)</span></span>
<span id="cb47-8"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb47-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-9"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb47-9" aria-hidden="true" tabindex="-1"></a><span class="co">    plt.annotate(tsne_df['word'][i],</span></span>
<span id="cb47-10"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb47-10" aria-hidden="true" tabindex="-1"></a><span class="co">                 xy=(tsne_df['tsne_x'][i], tsne_df['tsne_y'][i]),</span></span>
<span id="cb47-11"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb47-11" aria-hidden="true" tabindex="-1"></a><span class="co">                 xytext=(5, 2),</span></span>
<span id="cb47-12"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb47-12" aria-hidden="true" tabindex="-1"></a><span class="co">                 textcoords='offset points',</span></span>
<span id="cb47-13"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb47-13" aria-hidden="true" tabindex="-1"></a><span class="co">                 ha='right',</span></span>
<span id="cb47-14"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb47-14" aria-hidden="true" tabindex="-1"></a><span class="co">                 va='bottom')</span></span>
<span id="cb47-15"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb47-15" aria-hidden="true" tabindex="-1"></a><span class="co">plt.title('Word2Vec TSNE plot with min_count 25 and perplexity 40')</span></span>
<span id="cb47-16"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb47-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-17"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb47-17" aria-hidden="true" tabindex="-1"></a><span class="co">#save the figure into a file</span></span>
<span id="cb47-18"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb47-18" aria-hidden="true" tabindex="-1"></a><span class="co">plt.savefig('figures/word2vec/tsne_25_40.png', format="png")</span></span>
<span id="cb47-19"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb47-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-20"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb47-20" aria-hidden="true" tabindex="-1"></a><span class="co">#save the image object as a pickle file</span></span>
<span id="cb47-21"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb47-21" aria-hidden="true" tabindex="-1"></a><span class="co">with open('figures/pickle_data/tsne_25_40.pickle', 'wb') as f:</span></span>
<span id="cb47-22"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb47-22" aria-hidden="true" tabindex="-1"></a><span class="co">    pickle.dump(fig, f)</span></span>
<span id="cb47-23"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb47-23" aria-hidden="true" tabindex="-1"></a><span class="co">'''</span></span>
<span id="cb47-24"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb47-24" aria-hidden="true" tabindex="-1"></a><span class="co">#save the image object as a pickle file</span></span>
<span id="cb47-25"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb47-25" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(<span class="st">'figures/pickle_data/tsne_25_40.pickle'</span>, <span class="st">'rb'</span>) <span class="im">as</span> f:</span>
<span id="cb47-26"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb47-26" aria-hidden="true" tabindex="-1"></a>    fig <span class="op">=</span> pickle.load(f)</span>
<span id="cb47-27"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb47-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-28"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb47-28" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="./Report_files/cell-35-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>It might be difficult vizualize the plot above, so let’s plot with a greater n_count to create a word2vec model that’s more selective. <br></p>
<p>The model only trains or uses words larger than min_count, so by increasing the parameter min_count, we can lessen the amount of words used. <br></p>
<p>Let’s try other min_count to vizualize! Let’s make plotting the plot into a function to make it easier to read.</p>
<p><strong>Plot Function:</strong></p>
<div class="cell" data-execution_count="35">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Let's create a function to make it easier to plot the t-sne viz</span></span>
<span id="cb48-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb48-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb48-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> create_tsne_plot(model, filename, min_count, perplexity):</span>
<span id="cb48-4"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb48-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">#let's create a list of unique words</span></span>
<span id="cb48-5"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb48-5" aria-hidden="true" tabindex="-1"></a>    words_list <span class="op">=</span> model.wv.index_to_key</span>
<span id="cb48-6"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb48-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-7"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb48-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">#get each word vectors into a list</span></span>
<span id="cb48-8"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb48-8" aria-hidden="true" tabindex="-1"></a>    word_vectors <span class="op">=</span> []</span>
<span id="cb48-9"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb48-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-10"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb48-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> word <span class="kw">in</span> words_list:</span>
<span id="cb48-11"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb48-11" aria-hidden="true" tabindex="-1"></a>        word_vectors.append(model.wv[word])</span>
<span id="cb48-12"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb48-12" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb48-13"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb48-13" aria-hidden="true" tabindex="-1"></a>    <span class="co">#create an instance of T-SNE</span></span>
<span id="cb48-14"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb48-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># n_components is the dimensions of the lower dimension space</span></span>
<span id="cb48-15"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb48-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># perplexity is proportionally how many neighbors</span></span>
<span id="cb48-16"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb48-16" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb48-17"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb48-17" aria-hidden="true" tabindex="-1"></a>    tsne_mod <span class="op">=</span> TSNE(n_components<span class="op">=</span><span class="dv">2</span>, perplexity<span class="op">=</span>perplexity, n_iter<span class="op">=</span><span class="dv">2500</span>, random_state<span class="op">=</span>seed,</span>
<span id="cb48-18"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb48-18" aria-hidden="true" tabindex="-1"></a>                   init<span class="op">=</span><span class="st">'pca'</span>,learning_rate<span class="op">=</span><span class="dv">200</span>)</span>
<span id="cb48-19"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb48-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-20"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb48-20" aria-hidden="true" tabindex="-1"></a>    <span class="co">#fit and transform tsne on every word vector</span></span>
<span id="cb48-21"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb48-21" aria-hidden="true" tabindex="-1"></a>    wv_mod_tsne <span class="op">=</span> tsne_mod.fit_transform(word_vectors)</span>
<span id="cb48-22"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb48-22" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb48-23"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb48-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># make the dataframe</span></span>
<span id="cb48-24"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb48-24" aria-hidden="true" tabindex="-1"></a>    tsne_df <span class="op">=</span> pd.DataFrame(<span class="bu">list</span>(<span class="bu">zip</span>(words_list,wv_mod_tsne[:,<span class="dv">0</span>],wv_mod_tsne[:,<span class="dv">1</span>])), </span>
<span id="cb48-25"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb48-25" aria-hidden="true" tabindex="-1"></a>                       columns<span class="op">=</span>[<span class="st">'word'</span>,<span class="st">'tsne_x'</span>,<span class="st">'tsne_y'</span>])</span>
<span id="cb48-26"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb48-26" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb48-27"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb48-27" aria-hidden="true" tabindex="-1"></a>    <span class="co">#plotting code from https://www.kaggle.com/code/jeffd23/visualizing-word-vectors-with-t-sne/notebook</span></span>
<span id="cb48-28"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb48-28" aria-hidden="true" tabindex="-1"></a>    fig <span class="op">=</span> plt.figure(figsize<span class="op">=</span>(<span class="dv">16</span>, <span class="dv">16</span>))</span>
<span id="cb48-29"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb48-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(tsne_df[<span class="st">'word'</span>])):</span>
<span id="cb48-30"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb48-30" aria-hidden="true" tabindex="-1"></a>        plt.scatter(tsne_df[<span class="st">'tsne_x'</span>][i],tsne_df[<span class="st">'tsne_y'</span>][i], s<span class="op">=</span><span class="dv">50</span>)</span>
<span id="cb48-31"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb48-31" aria-hidden="true" tabindex="-1"></a>        plt.annotate(tsne_df[<span class="st">'word'</span>][i],</span>
<span id="cb48-32"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb48-32" aria-hidden="true" tabindex="-1"></a>                         xy<span class="op">=</span>(tsne_df[<span class="st">'tsne_x'</span>][i], tsne_df[<span class="st">'tsne_y'</span>][i]),</span>
<span id="cb48-33"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb48-33" aria-hidden="true" tabindex="-1"></a>                         xytext<span class="op">=</span>(<span class="dv">5</span>, <span class="dv">2</span>),</span>
<span id="cb48-34"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb48-34" aria-hidden="true" tabindex="-1"></a>                         textcoords<span class="op">=</span><span class="st">'offset points'</span>,</span>
<span id="cb48-35"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb48-35" aria-hidden="true" tabindex="-1"></a>                         ha<span class="op">=</span><span class="st">'right'</span>,</span>
<span id="cb48-36"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb48-36" aria-hidden="true" tabindex="-1"></a>                         va<span class="op">=</span><span class="st">'bottom'</span>)</span>
<span id="cb48-37"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb48-37" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'Word2Vec TSNE plot with min_count </span><span class="sc">{}</span><span class="st"> and perplexity </span><span class="sc">{}</span><span class="st">'</span>.<span class="bu">format</span>(</span>
<span id="cb48-38"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb48-38" aria-hidden="true" tabindex="-1"></a>    min_count, perplexity))</span>
<span id="cb48-39"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb48-39" aria-hidden="true" tabindex="-1"></a>    <span class="co">#save the figure to make it easier to load    </span></span>
<span id="cb48-40"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb48-40" aria-hidden="true" tabindex="-1"></a>    savepath <span class="op">=</span> <span class="st">'figures/word2vec/'</span> <span class="op">+</span> filename <span class="op">+</span> <span class="st">'.png'</span></span>
<span id="cb48-41"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb48-41" aria-hidden="true" tabindex="-1"></a>    plt.savefig(savepath, <span class="bu">format</span><span class="op">=</span><span class="st">'png'</span>)</span>
<span id="cb48-42"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb48-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-43"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb48-43" aria-hidden="true" tabindex="-1"></a>    <span class="co">#save the image object as a pickle file</span></span>
<span id="cb48-44"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb48-44" aria-hidden="true" tabindex="-1"></a>    picklepath <span class="op">=</span> <span class="st">'figures/pickle_data/'</span> <span class="op">+</span> filename <span class="op">+</span> <span class="st">'.pickle'</span></span>
<span id="cb48-45"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb48-45" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> <span class="bu">open</span>(picklepath, <span class="st">'wb'</span>) <span class="im">as</span> f:</span>
<span id="cb48-46"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb48-46" aria-hidden="true" tabindex="-1"></a>        pickle.dump(fig, f)</span>
<span id="cb48-47"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb48-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-48"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb48-48" aria-hidden="true" tabindex="-1"></a>    plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><strong>t-SNE (min_count = 50, perplexity = 40):</strong></p>
<div class="cell" data-execution_count="36">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="co">'''</span></span>
<span id="cb49-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb49-2" aria-hidden="true" tabindex="-1"></a><span class="co">wv_mod_50 = word2vec.Word2Vec(X_train_clean, min_count=50)</span></span>
<span id="cb49-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb49-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-4"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb49-4" aria-hidden="true" tabindex="-1"></a><span class="co">create_tsne_plot(wv_mod_50, 'tsne_50_40', 50, 40)</span></span>
<span id="cb49-5"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb49-5" aria-hidden="true" tabindex="-1"></a><span class="co">'''</span></span>
<span id="cb49-6"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb49-6" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(<span class="st">'figures/pickle_data/tsne_50_40.pickle'</span>, <span class="st">'rb'</span>) <span class="im">as</span> f:</span>
<span id="cb49-7"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb49-7" aria-hidden="true" tabindex="-1"></a>    fig <span class="op">=</span> pickle.load(f)</span>
<span id="cb49-8"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb49-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-9"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb49-9" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="./Report_files/cell-37-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>It gets easier to see when we increase min_count to 50! You can start to see how Word2Vec captures semantic information.</p>
<p>Interesting points from the plot:</p>
<ol type="1">
<li>(would recommend) and (video, watch) are very close. This shows that the model takes into account words that are often with each other.</li>
<li>(page, book) and (author, written, character) are also very close. This shows that the model can map similarity between words from word frequency.</li>
<li>(dvd, review) are far away. This shows that dvd and review are rarely with each other.</li>
</ol>
<p>Honestly, this is super interesting to me! This vizualization gives us a nuanced representation of words in our review.</p>
<p>Let’s try different min_counts. Let’s keep perplexity of t-SNE to 40.</p>
<p><strong>t-SNE (min_count = 100, perplexity = 40):</strong></p>
<div class="cell" data-execution_count="37">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="co">'''</span></span>
<span id="cb50-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb50-2" aria-hidden="true" tabindex="-1"></a><span class="co">wv_mod_100 = word2vec.Word2Vec(X_train_clean, min_count=100)</span></span>
<span id="cb50-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb50-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-4"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb50-4" aria-hidden="true" tabindex="-1"></a><span class="co">create_tsne_plot(wv_mod_100, 'tsne_100_40', 100, 40)</span></span>
<span id="cb50-5"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb50-5" aria-hidden="true" tabindex="-1"></a><span class="co">'''</span></span>
<span id="cb50-6"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb50-6" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(<span class="st">'figures/pickle_data/tsne_100_40.pickle'</span>, <span class="st">'rb'</span>) <span class="im">as</span> f:</span>
<span id="cb50-7"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb50-7" aria-hidden="true" tabindex="-1"></a>    fig <span class="op">=</span> pickle.load(f)</span>
<span id="cb50-8"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb50-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-9"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb50-9" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="./Report_files/cell-38-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>As you can see, the larger the min_count, the less words our Word2Vec model uses to train the model. However, this creates a clearer plot for our more common words.</p>
<p><strong>t-SNE (min_count = 200, perplexity = 40):</strong></p>
<div class="cell" data-execution_count="38">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="co">'''</span></span>
<span id="cb51-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb51-2" aria-hidden="true" tabindex="-1"></a><span class="co">wv_mod_200 = word2vec.Word2Vec(X_train_clean, min_count=200)</span></span>
<span id="cb51-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb51-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-4"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb51-4" aria-hidden="true" tabindex="-1"></a><span class="co">create_tsne_plot(wv_mod_200, 'tsne_200_40', 200, 40)</span></span>
<span id="cb51-5"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb51-5" aria-hidden="true" tabindex="-1"></a><span class="co">'''</span></span>
<span id="cb51-6"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb51-6" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(<span class="st">'figures/pickle_data/tsne_200_40.pickle'</span>, <span class="st">'rb'</span>) <span class="im">as</span> f:</span>
<span id="cb51-7"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb51-7" aria-hidden="true" tabindex="-1"></a>    fig <span class="op">=</span> pickle.load(f)</span>
<span id="cb51-8"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb51-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-9"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb51-9" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="./Report_files/cell-39-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>It gets even sparser, this shows what words are most common. Let’s try a very very large min_count.</p>
<p><strong>t-SNE (min_count = 500, perplexity = 40):</strong></p>
<div class="cell" data-execution_count="39">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="co">'''</span></span>
<span id="cb52-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb52-2" aria-hidden="true" tabindex="-1"></a><span class="co">wv_mod_500 = word2vec.Word2Vec(X_train_clean, min_count=500)</span></span>
<span id="cb52-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb52-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-4"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb52-4" aria-hidden="true" tabindex="-1"></a><span class="co">create_tsne_plot(wv_mod_500, 'tsne_500_40', 500, 40)</span></span>
<span id="cb52-5"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb52-5" aria-hidden="true" tabindex="-1"></a><span class="co">'''</span></span>
<span id="cb52-6"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb52-6" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(<span class="st">'figures/pickle_data/tsne_500_40.pickle'</span>, <span class="st">'rb'</span>) <span class="im">as</span> f:</span>
<span id="cb52-7"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb52-7" aria-hidden="true" tabindex="-1"></a>    fig <span class="op">=</span> pickle.load(f)</span>
<span id="cb52-8"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb52-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-9"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb52-9" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="./Report_files/cell-40-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>Ah, there are barely any more words anymore, as only words that occurs more than 500 times will be included.</p>
<p>When min_count gets really large, the Word2Vec model gets really selective. This makes it not really that good for modelling as we don’t have much information. For vizualizing, min_count of 25 and 50 is really clear.</p>
<p>We can see that terms like <strong>month</strong> and <strong>year</strong> is very close, while it’s very far from terms like <strong>car</strong>. This shows that the Word2Vec model basically captures a word’s similarity with other words. Though, you may notice from the vizualization that some words are close together for no reason, and that’s normal as Word2Vec performs worse when our the length of our sentences, reviews in our case, are short as it doesn’t have too much contextual information.</p>
<p>Nonetheless, I hope from looking at these vizualizations we can see what Word2Vec captures, which is similarity between words by training on a word’s context in the corpus.</p>
<p><strong>Honestly these graphs are really cool to me!</strong></p>
<p>From this, let’s use min_count of 1 as the most a information.</p>
<p>But first we have to transform the W2V model to a format that scikitlearn can use, because it’s from different packages.</p>
<div class="cell" data-execution_count="40">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Let's create an instance of a Word2Vec model trained on the processed tokens</span></span>
<span id="cb53-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb53-2" aria-hidden="true" tabindex="-1"></a>wv_mod_1 <span class="op">=</span> word2vec.Word2Vec(X_train_clean, min_count<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb53-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb53-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-4"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb53-4" aria-hidden="true" tabindex="-1"></a><span class="co">#Let's make the previous steps into a function to apply to the test set later</span></span>
<span id="cb53-5"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb53-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> create_w2v_df(wv_mod):</span>
<span id="cb53-6"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb53-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-7"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb53-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">#let's create a list of unique words</span></span>
<span id="cb53-8"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb53-8" aria-hidden="true" tabindex="-1"></a>    words_list <span class="op">=</span> wv_mod.wv.index_to_key</span>
<span id="cb53-9"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb53-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-10"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb53-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">#get each word vectors into a list</span></span>
<span id="cb53-11"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb53-11" aria-hidden="true" tabindex="-1"></a>    X_wv <span class="op">=</span> []</span>
<span id="cb53-12"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb53-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-13"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb53-13" aria-hidden="true" tabindex="-1"></a>    <span class="co">#get a list of word vectors</span></span>
<span id="cb53-14"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb53-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> word <span class="kw">in</span> words_list:</span>
<span id="cb53-15"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb53-15" aria-hidden="true" tabindex="-1"></a>        X_wv.append(wv_mod.wv[word])</span>
<span id="cb53-16"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb53-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-17"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb53-17" aria-hidden="true" tabindex="-1"></a>    <span class="co">#return the np.array of the list of word vectors</span></span>
<span id="cb53-18"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb53-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span>(np.array(X_wv))</span>
<span id="cb53-19"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb53-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-20"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb53-20" aria-hidden="true" tabindex="-1"></a>X_train_wv <span class="op">=</span> create_w2v_df(wv_mod_1)</span>
<span id="cb53-21"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb53-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'The shape of the Word2Vec transformed training set is: </span><span class="sc">{}</span><span class="st">'</span>.<span class="bu">format</span>(X_train_wv.shape))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>The shape of the Word2Vec transformed training set is: (14446, 100)</code></pre>
</div>
</div>
<p>You may have noticed that this is the wrong shape for our dataset to feed into the model. Instead of turning each review into a combination of values, we have instead mapped each word into a 100-dimension vector space. Our resulting dataset doesn’t scores for every sentence, but scores for every word. We basically represented every word in our dataset but not represented every review.</p>
<p>To perform machine learning, we have to transform this dataset into a dataset with a review for each row and every column representing values for each word.</p>
<p>There are some ways to do this, but one way I read is to multiply each word with its tf-idf weights to produce a weighted average for word for each review. However, Another more simpler way is to use <strong>Doc2Vec</strong>.</p>
<p>Doc2Vec creates a vector space for every sentence instead of words, and this is handy for training as we don’t have to do extra work in using the word representation of Word2Vec to create a numerical representation of sentences. It uses the same concept as Word2Vec but keeps a unique review id for every review. I won’t go much into detail as it’s honestly complicated. But to start, we need to tag each review using the TaggedDocument package from Gensim.</p>
<blockquote class="blockquote">
<p>To read more, there is a medium article on this: https://medium.com/wisio/a-gentle-introduction-to-doc2vec-db3e8c0cce5e</p>
</blockquote>
</section>
<section id="doc2vec" class="level3">
<h3 class="anchored" data-anchor-id="doc2vec">Doc2Vec<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#doc2vec" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h3>
<div class="cell" data-execution_count="41">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="co">#tagging each row a unique identifier</span></span>
<span id="cb55-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb55-2" aria-hidden="true" tabindex="-1"></a><span class="co">#code from Doc2Vec API page: https://radimrehurek.com/gensim/models/doc2vec.html</span></span>
<span id="cb55-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb55-3" aria-hidden="true" tabindex="-1"></a>doc_clean <span class="op">=</span> [TaggedDocument(doc, [i]) <span class="cf">for</span> i, doc <span class="kw">in</span> <span class="bu">enumerate</span>(X_train_clean)]</span>
<span id="cb55-4"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb55-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-5"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb55-5" aria-hidden="true" tabindex="-1"></a>doc_clean[<span class="dv">0</span>:<span class="dv">2</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="41">
<pre><code>[TaggedDocument(words=['used', 'product', 'day', 'ago', 'stopped', 'raining', 'since', 'two', 'day', 'slug', 'guess', 'rain', 'lately', 'many', 'patio', 'crawling', 'exterior', 'wall', 'even', 'sit', 'outside', 'evening', 'gross', 'thrilled', 'product'], tags=[0]),
 TaggedDocument(words=['math', 'genius', 'remember', 'enough', 'concept', 'spot', 'mistake', 'math', 'pretty', 'bad', 'sign', 'find', 'error', 'first', 'page', 'book', 'one', 'error', 'incorrect', 'solution', 'equation'], tags=[1])]</code></pre>
</div>
</div>
<p>As you can see, every review is now a list of tokens and contain a unique identifier. This is the format the Doc2Vec model needs.</p>
<p>Now let’s apply our Doc2Vec model to our dataset to represent our reviews.</p>
<div class="cell" data-execution_count="42">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="co">'''</span></span>
<span id="cb57-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb57-2" aria-hidden="true" tabindex="-1"></a><span class="co">#creating an instance of Doc2Vec (min_count = 1, vector_size=200)</span></span>
<span id="cb57-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb57-3" aria-hidden="true" tabindex="-1"></a><span class="co">d2v_mod = Doc2Vec(doc_clean,vector_size=200, min_count=1, workers=8, epochs = 100, seed = seed)</span></span>
<span id="cb57-4"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb57-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-5"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb57-5" aria-hidden="true" tabindex="-1"></a><span class="co">#save our fitted model</span></span>
<span id="cb57-6"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb57-6" aria-hidden="true" tabindex="-1"></a><span class="co">with open('models/d2v.pickle', 'wb') as f:</span></span>
<span id="cb57-7"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb57-7" aria-hidden="true" tabindex="-1"></a><span class="co">    pickle.dump(d2v_mod, f)</span></span>
<span id="cb57-8"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb57-8" aria-hidden="true" tabindex="-1"></a><span class="co">'''</span></span>
<span id="cb57-9"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb57-9" aria-hidden="true" tabindex="-1"></a><span class="co">#load our fitted model</span></span>
<span id="cb57-10"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb57-10" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(<span class="st">'models/d2v.pickle'</span>, <span class="st">'rb'</span>) <span class="im">as</span> f:</span>
<span id="cb57-11"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb57-11" aria-hidden="true" tabindex="-1"></a>    d2v_mod <span class="op">=</span> pickle.load(f)</span>
<span id="cb57-12"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb57-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-13"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb57-13" aria-hidden="true" tabindex="-1"></a><span class="co">#now let's extract our vector representations from the model using .infer_vector()</span></span>
<span id="cb57-14"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb57-14" aria-hidden="true" tabindex="-1"></a>doc_vector <span class="op">=</span> []</span>
<span id="cb57-15"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb57-15" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(X_train_clean)):</span>
<span id="cb57-16"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb57-16" aria-hidden="true" tabindex="-1"></a>    doc_vector.append(d2v_mod.infer_vector((X_train_clean.reset_index(drop<span class="op">=</span><span class="va">True</span>)[i])))</span>
<span id="cb57-17"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb57-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-18"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb57-18" aria-hidden="true" tabindex="-1"></a><span class="co">#convert the list of vectors into an array</span></span>
<span id="cb57-19"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb57-19" aria-hidden="true" tabindex="-1"></a>X_train_dv <span class="op">=</span> np.array(doc_vector)</span>
<span id="cb57-20"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb57-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'The raw shape of our training set is: </span><span class="sc">{}</span><span class="st">'</span>.<span class="bu">format</span>(X_train_clean.shape))</span>
<span id="cb57-21"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb57-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'The resulting shape of our dataframe is: </span><span class="sc">{}</span><span class="st">'</span>.<span class="bu">format</span>(X_train_dv.shape))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>The raw shape of our training set is: (2680,)
The resulting shape of our dataframe is: (2680, 200)</code></pre>
</div>
</div>
<p>It’s the same number of rows rows as our training set, Finally after all that time, we can move onto modelling!</p>
<p><strong>Doc2Vec Function:</strong></p>
<div class="cell" data-execution_count="43">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Since our previous function only takes an input of a string, we now create a new one that applys to every row</span></span>
<span id="cb59-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb59-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> preprocess_df(x):</span>
<span id="cb59-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb59-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> x.<span class="bu">apply</span>(<span class="kw">lambda</span> x: preprocess_text(x))</span>
<span id="cb59-4"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb59-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-5"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb59-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-6"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb59-6" aria-hidden="true" tabindex="-1"></a><span class="co">#Let's make a function to make this easier to do it to the data</span></span>
<span id="cb59-7"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb59-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> transform_doc2Vec(input_df, model<span class="op">=</span>d2v_mod):</span>
<span id="cb59-8"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb59-8" aria-hidden="true" tabindex="-1"></a>    <span class="co">#cleaning our text</span></span>
<span id="cb59-9"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb59-9" aria-hidden="true" tabindex="-1"></a>    clean_text <span class="op">=</span> preprocess_df(input_df)</span>
<span id="cb59-10"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb59-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb59-11"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb59-11" aria-hidden="true" tabindex="-1"></a>    <span class="co">#tagging each row a unique identifier</span></span>
<span id="cb59-12"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb59-12" aria-hidden="true" tabindex="-1"></a>    doc_clean <span class="op">=</span> [TaggedDocument(doc, [i]) <span class="cf">for</span> i, doc <span class="kw">in</span> <span class="bu">enumerate</span>(clean_text)]</span>
<span id="cb59-13"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb59-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb59-14"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb59-14" aria-hidden="true" tabindex="-1"></a>    <span class="co">#now let's extract our vector representations from the model using .infer_vector()</span></span>
<span id="cb59-15"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb59-15" aria-hidden="true" tabindex="-1"></a>    doc_vector <span class="op">=</span> []</span>
<span id="cb59-16"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb59-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(clean_text)):</span>
<span id="cb59-17"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb59-17" aria-hidden="true" tabindex="-1"></a>        doc_vector.append(model.infer_vector((clean_text.reset_index(drop<span class="op">=</span><span class="va">True</span>)[i])))</span>
<span id="cb59-18"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb59-18" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb59-19"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb59-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.array(doc_vector)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
</section>
</section>
<section id="modelling" class="level1">
<h1>Modelling</h1>
<p>Let’s recap the word embedded we have:</p>
<ol type="1">
<li>Bag of Words (X_train_bow)</li>
<li>TF-IDF (X_train_tfidf)</li>
<li>Doc2Vec or Word2Vec (X_train_dv)</li>
</ol>
<p>List of models I want to try for classification:</p>
<ol type="1">
<li>Logistic Regression w/ Penalty</li>
<li>Support Vector Machines</li>
<li>K-nearest Neighbors</li>
<li>Random Forest Classifier</li>
</ol>
<p>For each model we’re going to use, let’s compare the three word embedding’s performances!</p>
<p>To do this, let’s create a pipeline, Sci-kit learn’s idea of a workflow in tidymodels. I could make all the models into one pipeline, but I want to compare each word embedding against each other, so I won’t do it here.</p>
<p>We can’t immediately use our custom pre-processing function into the pipeline. But we can create a function wrapper of it and then use that in the pipeline. To do this, we will use the Function Transformer function from sklearn.</p>
<p>Also, since TF-IDF is just a better Bag of Words, I will only use it on the first model: Logistic Regression.</p>
<p><strong>Pipeline initialization:</strong></p>
<div class="cell" data-execution_count="44">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="co">#doc2vec wrapper function</span></span>
<span id="cb60-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-2" aria-hidden="true" tabindex="-1"></a>doc2vec <span class="op">=</span> FunctionTransformer(transform_doc2Vec)</span>
<span id="cb60-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-4"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-4" aria-hidden="true" tabindex="-1"></a><span class="co">#create pipeline:</span></span>
<span id="cb60-5"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-6"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-6" aria-hidden="true" tabindex="-1"></a><span class="co">#LogReg </span></span>
<span id="cb60-7"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-7" aria-hidden="true" tabindex="-1"></a>bow_logreg_p <span class="op">=</span> Pipeline(steps<span class="op">=</span>[</span>
<span id="cb60-8"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-8" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'cv'</span>, CountVectorizer(tokenizer<span class="op">=</span>preprocess_text)),</span>
<span id="cb60-9"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-9" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'classifier'</span>, LogisticRegression(random_state<span class="op">=</span>seed))</span>
<span id="cb60-10"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-10" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb60-11"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-12"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-12" aria-hidden="true" tabindex="-1"></a>tfidf_logreg_p <span class="op">=</span> Pipeline(steps<span class="op">=</span>[</span>
<span id="cb60-13"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-13" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'tfidf'</span>, TfidfVectorizer(tokenizer<span class="op">=</span>preprocess_text)),</span>
<span id="cb60-14"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-14" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'classifier'</span>, LogisticRegression(random_state<span class="op">=</span>seed))</span>
<span id="cb60-15"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-15" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb60-16"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-17"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-17" aria-hidden="true" tabindex="-1"></a>d2v_logreg_p <span class="op">=</span> Pipeline(steps<span class="op">=</span>[</span>
<span id="cb60-18"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-18" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'d2v'</span>, doc2vec),</span>
<span id="cb60-19"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-19" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'classifier'</span>, LogisticRegression(random_state<span class="op">=</span>seed))</span>
<span id="cb60-20"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-20" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb60-21"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-22"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-22" aria-hidden="true" tabindex="-1"></a><span class="co">#Support Vector Machines</span></span>
<span id="cb60-23"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-23" aria-hidden="true" tabindex="-1"></a>tfidf_SVC_p <span class="op">=</span> Pipeline(steps<span class="op">=</span>[</span>
<span id="cb60-24"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-24" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'tfidf'</span>, TfidfVectorizer(tokenizer<span class="op">=</span>preprocess_text)),</span>
<span id="cb60-25"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-25" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'classifier'</span>, SVC())</span>
<span id="cb60-26"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-26" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb60-27"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-28"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-28" aria-hidden="true" tabindex="-1"></a>d2v_SVC_p <span class="op">=</span> Pipeline(steps<span class="op">=</span>[</span>
<span id="cb60-29"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-29" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'d2v'</span>, doc2vec),</span>
<span id="cb60-30"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-30" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'classifier'</span>, SVC())</span>
<span id="cb60-31"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-31" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb60-32"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-33"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-33" aria-hidden="true" tabindex="-1"></a><span class="co">#KNN </span></span>
<span id="cb60-34"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-34" aria-hidden="true" tabindex="-1"></a>tfidf_knn_p <span class="op">=</span> Pipeline(steps<span class="op">=</span>[</span>
<span id="cb60-35"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-35" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'tfidf'</span>, TfidfVectorizer(tokenizer<span class="op">=</span>preprocess_text)),</span>
<span id="cb60-36"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-36" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'classifier'</span>, KNeighborsClassifier())</span>
<span id="cb60-37"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-37" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb60-38"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-39"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-39" aria-hidden="true" tabindex="-1"></a>d2v_knn_p <span class="op">=</span> Pipeline(steps<span class="op">=</span>[</span>
<span id="cb60-40"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-40" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'d2v'</span>, doc2vec),</span>
<span id="cb60-41"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-41" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'classifier'</span>, KNeighborsClassifier())</span>
<span id="cb60-42"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-42" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb60-43"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-44"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-44" aria-hidden="true" tabindex="-1"></a><span class="co">#Random Forest Classifier</span></span>
<span id="cb60-45"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-45" aria-hidden="true" tabindex="-1"></a>tfidf_rf_p <span class="op">=</span> Pipeline(steps<span class="op">=</span>[</span>
<span id="cb60-46"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-46" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'tfidf'</span>, TfidfVectorizer(tokenizer<span class="op">=</span>preprocess_text)),</span>
<span id="cb60-47"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-47" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'classifier'</span>, RandomForestClassifier(random_state<span class="op">=</span>seed))</span>
<span id="cb60-48"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-48" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb60-49"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-50"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-50" aria-hidden="true" tabindex="-1"></a>d2v_rf_p <span class="op">=</span> Pipeline(steps<span class="op">=</span>[</span>
<span id="cb60-51"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-51" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'d2v'</span>, doc2vec),</span>
<span id="cb60-52"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-52" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'classifier'</span>, RandomForestClassifier(random_state<span class="op">=</span>seed))</span>
<span id="cb60-53"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-53" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb60-54"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-55"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-55" aria-hidden="true" tabindex="-1"></a><span class="co">#parameter grids</span></span>
<span id="cb60-56"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-56" aria-hidden="true" tabindex="-1"></a>param_range <span class="op">=</span> [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>]</span>
<span id="cb60-57"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-57" aria-hidden="true" tabindex="-1"></a>param_range_fl <span class="op">=</span> [<span class="fl">1.0</span>, <span class="fl">0.5</span>, <span class="fl">0.1</span>]</span>
<span id="cb60-58"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-58" aria-hidden="true" tabindex="-1"></a>n_estimators <span class="op">=</span> [<span class="dv">50</span>,<span class="dv">100</span>,<span class="dv">150</span>]</span>
<span id="cb60-59"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-59" aria-hidden="true" tabindex="-1"></a>learning_rates <span class="op">=</span> [<span class="fl">.1</span>,<span class="fl">.2</span>,<span class="fl">.3</span>]</span>
<span id="cb60-60"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-61"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-61" aria-hidden="true" tabindex="-1"></a><span class="co">#parameter grid from https://ryan-reilly.medium.com/gridsearch-pipelines-of-multiple-models-on-multiclass-classification-e9124b6ea2e3</span></span>
<span id="cb60-62"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-63"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-63" aria-hidden="true" tabindex="-1"></a>lr_param_grid <span class="op">=</span> [{<span class="st">'classifier__penalty'</span>: [<span class="st">'l1'</span>, <span class="st">'l2'</span>],</span>
<span id="cb60-64"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-64" aria-hidden="true" tabindex="-1"></a>                   <span class="st">'classifier__C'</span>: param_range_fl,</span>
<span id="cb60-65"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-65" aria-hidden="true" tabindex="-1"></a>                   <span class="st">'classifier__solver'</span>: [<span class="st">'liblinear'</span>]}]</span>
<span id="cb60-66"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-67"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-67" aria-hidden="true" tabindex="-1"></a>svm_param_grid <span class="op">=</span> [{<span class="st">'classifier__kernel'</span>: [<span class="st">'linear'</span>, <span class="st">'rbf'</span>], </span>
<span id="cb60-68"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-68" aria-hidden="true" tabindex="-1"></a>                    <span class="st">'classifier__C'</span>: [<span class="fl">0.1</span>, <span class="dv">1</span>, <span class="dv">10</span>, <span class="dv">100</span>, <span class="dv">1000</span>]}]</span>
<span id="cb60-69"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-70"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-70" aria-hidden="true" tabindex="-1"></a>knn_param_grid <span class="op">=</span> [{<span class="st">'classifier__n_neighbors'</span>: param_range,</span>
<span id="cb60-71"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-71" aria-hidden="true" tabindex="-1"></a>                   <span class="st">'classifier__weights'</span>: [<span class="st">'uniform'</span>, <span class="st">'distance'</span>],</span>
<span id="cb60-72"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-72" aria-hidden="true" tabindex="-1"></a>                   <span class="st">'classifier__metric'</span>: [<span class="st">'euclidean'</span>, <span class="st">'manhattan'</span>]}]</span>
<span id="cb60-73"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-74"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-74" aria-hidden="true" tabindex="-1"></a>rf_param_grid <span class="op">=</span> [{<span class="st">'classifier__min_samples_leaf'</span>: param_range,</span>
<span id="cb60-75"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-75" aria-hidden="true" tabindex="-1"></a>                   <span class="st">'classifier__max_depth'</span>: param_range,</span>
<span id="cb60-76"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-76" aria-hidden="true" tabindex="-1"></a>                   <span class="st">'classifier__min_samples_split'</span>: param_range[<span class="dv">1</span>:]}]</span>
<span id="cb60-77"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-78"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-78" aria-hidden="true" tabindex="-1"></a><span class="co">#GridSearch Pipelines for hyperparameter tuning</span></span>
<span id="cb60-79"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-80"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-80" aria-hidden="true" tabindex="-1"></a>bow_lr_grid_search <span class="op">=</span> GridSearchCV(estimator<span class="op">=</span>bow_logreg_p,</span>
<span id="cb60-81"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-81" aria-hidden="true" tabindex="-1"></a>        param_grid<span class="op">=</span>lr_param_grid,</span>
<span id="cb60-82"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-82" aria-hidden="true" tabindex="-1"></a>        n_jobs <span class="op">=</span> <span class="op">-</span><span class="dv">1</span>,</span>
<span id="cb60-83"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-83" aria-hidden="true" tabindex="-1"></a>        scoring<span class="op">=</span><span class="st">'roc_auc'</span>,</span>
<span id="cb60-84"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-84" aria-hidden="true" tabindex="-1"></a>        cv<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb60-85"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-86"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-86" aria-hidden="true" tabindex="-1"></a>tfidf_lr_grid_search <span class="op">=</span> GridSearchCV(estimator<span class="op">=</span>tfidf_logreg_p,</span>
<span id="cb60-87"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-87" aria-hidden="true" tabindex="-1"></a>        param_grid<span class="op">=</span>lr_param_grid,</span>
<span id="cb60-88"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-88" aria-hidden="true" tabindex="-1"></a>        n_jobs <span class="op">=</span> <span class="op">-</span><span class="dv">1</span>,</span>
<span id="cb60-89"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-89" aria-hidden="true" tabindex="-1"></a>        scoring<span class="op">=</span><span class="st">'roc_auc'</span>,</span>
<span id="cb60-90"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-90" aria-hidden="true" tabindex="-1"></a>        cv<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb60-91"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-91" aria-hidden="true" tabindex="-1"></a>tfidf_rf_grid_search <span class="op">=</span> GridSearchCV(estimator<span class="op">=</span>tfidf_rf_p,</span>
<span id="cb60-92"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-92" aria-hidden="true" tabindex="-1"></a>        param_grid<span class="op">=</span>rf_param_grid,</span>
<span id="cb60-93"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-93" aria-hidden="true" tabindex="-1"></a>        n_jobs <span class="op">=</span> <span class="op">-</span><span class="dv">1</span>,</span>
<span id="cb60-94"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-94" aria-hidden="true" tabindex="-1"></a>        scoring<span class="op">=</span><span class="st">'roc_auc'</span>,</span>
<span id="cb60-95"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-95" aria-hidden="true" tabindex="-1"></a>        cv<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb60-96"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-96" aria-hidden="true" tabindex="-1"></a>tfidf_knn_grid_search <span class="op">=</span> GridSearchCV(estimator<span class="op">=</span>tfidf_knn_p,</span>
<span id="cb60-97"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-97" aria-hidden="true" tabindex="-1"></a>        param_grid<span class="op">=</span>knn_param_grid,</span>
<span id="cb60-98"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-98" aria-hidden="true" tabindex="-1"></a>        n_jobs <span class="op">=</span> <span class="op">-</span><span class="dv">1</span>,</span>
<span id="cb60-99"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-99" aria-hidden="true" tabindex="-1"></a>        scoring<span class="op">=</span><span class="st">'roc_auc'</span>,</span>
<span id="cb60-100"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-100" aria-hidden="true" tabindex="-1"></a>        cv<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb60-101"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-101" aria-hidden="true" tabindex="-1"></a>tfidf_svm_grid_search <span class="op">=</span> GridSearchCV(estimator<span class="op">=</span>tfidf_SVC_p,</span>
<span id="cb60-102"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-102" aria-hidden="true" tabindex="-1"></a>        param_grid<span class="op">=</span>svm_param_grid,</span>
<span id="cb60-103"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-103" aria-hidden="true" tabindex="-1"></a>        n_jobs <span class="op">=</span> <span class="op">-</span><span class="dv">1</span>,</span>
<span id="cb60-104"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-104" aria-hidden="true" tabindex="-1"></a>        scoring<span class="op">=</span><span class="st">'roc_auc'</span>,</span>
<span id="cb60-105"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-105" aria-hidden="true" tabindex="-1"></a>        cv<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb60-106"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-107"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-107" aria-hidden="true" tabindex="-1"></a>d2v_lr_grid_search <span class="op">=</span> GridSearchCV(estimator<span class="op">=</span>d2v_logreg_p,</span>
<span id="cb60-108"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-108" aria-hidden="true" tabindex="-1"></a>        param_grid<span class="op">=</span>lr_param_grid,</span>
<span id="cb60-109"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-109" aria-hidden="true" tabindex="-1"></a>        n_jobs <span class="op">=</span> <span class="op">-</span><span class="dv">1</span>,</span>
<span id="cb60-110"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-110" aria-hidden="true" tabindex="-1"></a>        scoring<span class="op">=</span><span class="st">'roc_auc'</span>,</span>
<span id="cb60-111"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-111" aria-hidden="true" tabindex="-1"></a>        cv<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb60-112"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-112" aria-hidden="true" tabindex="-1"></a>d2v_rf_grid_search <span class="op">=</span> GridSearchCV(estimator<span class="op">=</span>d2v_rf_p,</span>
<span id="cb60-113"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-113" aria-hidden="true" tabindex="-1"></a>        param_grid<span class="op">=</span>rf_param_grid,</span>
<span id="cb60-114"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-114" aria-hidden="true" tabindex="-1"></a>        n_jobs <span class="op">=</span> <span class="op">-</span><span class="dv">1</span>,</span>
<span id="cb60-115"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-115" aria-hidden="true" tabindex="-1"></a>        scoring<span class="op">=</span><span class="st">'roc_auc'</span>,</span>
<span id="cb60-116"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-116" aria-hidden="true" tabindex="-1"></a>        cv<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb60-117"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-117" aria-hidden="true" tabindex="-1"></a>d2v_knn_grid_search <span class="op">=</span> GridSearchCV(estimator<span class="op">=</span>d2v_knn_p,</span>
<span id="cb60-118"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-118" aria-hidden="true" tabindex="-1"></a>        param_grid<span class="op">=</span>knn_param_grid,</span>
<span id="cb60-119"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-119" aria-hidden="true" tabindex="-1"></a>        n_jobs <span class="op">=</span> <span class="op">-</span><span class="dv">1</span>,</span>
<span id="cb60-120"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-120" aria-hidden="true" tabindex="-1"></a>        scoring<span class="op">=</span><span class="st">'roc_auc'</span>,</span>
<span id="cb60-121"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-121" aria-hidden="true" tabindex="-1"></a>        cv<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb60-122"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-122" aria-hidden="true" tabindex="-1"></a>d2v_svm_grid_search <span class="op">=</span> GridSearchCV(estimator<span class="op">=</span>d2v_SVC_p,</span>
<span id="cb60-123"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-123" aria-hidden="true" tabindex="-1"></a>        param_grid<span class="op">=</span>svm_param_grid,</span>
<span id="cb60-124"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-124" aria-hidden="true" tabindex="-1"></a>        n_jobs <span class="op">=</span> <span class="op">-</span><span class="dv">1</span>,</span>
<span id="cb60-125"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-125" aria-hidden="true" tabindex="-1"></a>        scoring<span class="op">=</span><span class="st">'roc_auc'</span>,</span>
<span id="cb60-126"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb60-126" aria-hidden="true" tabindex="-1"></a>        cv<span class="op">=</span><span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<section id="model-fitting-with-hyperparameter-tuning-using-gridsearchcv" class="level3">
<h3 class="anchored" data-anchor-id="model-fitting-with-hyperparameter-tuning-using-gridsearchcv">Model Fitting with Hyperparameter tuning using GridSearchCV:<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#model-fitting-with-hyperparameter-tuning-using-gridsearchcv" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h3>
<p>The grid search fits the models using cross validation with k=3</p>
<div class="cell" data-execution_count="45">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="co">'''</span></span>
<span id="cb61-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb61-2" aria-hidden="true" tabindex="-1"></a><span class="co">#fit the models on the logistic regression instance</span></span>
<span id="cb61-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb61-3" aria-hidden="true" tabindex="-1"></a><span class="co">bow_lr_grid_search.fit(X_train, y_train)</span></span>
<span id="cb61-4"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb61-4" aria-hidden="true" tabindex="-1"></a><span class="co">tfidf_lr_grid_search.fit(X_train, y_train)</span></span>
<span id="cb61-5"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb61-5" aria-hidden="true" tabindex="-1"></a><span class="co">d2v_lr_grid_search.fit(X_train, y_train)</span></span>
<span id="cb61-6"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb61-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-7"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb61-7" aria-hidden="true" tabindex="-1"></a><span class="co">tfidf_svm_grid_search.fit(X_train, y_train)</span></span>
<span id="cb61-8"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb61-8" aria-hidden="true" tabindex="-1"></a><span class="co">d2v_svm_grid_search.fit(X_train, y_train)</span></span>
<span id="cb61-9"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb61-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-10"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb61-10" aria-hidden="true" tabindex="-1"></a><span class="co">tfidf_knn_grid_search.fit(X_train, y_train)</span></span>
<span id="cb61-11"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb61-11" aria-hidden="true" tabindex="-1"></a><span class="co">d2v_knn_grid_search.fit(X_train, y_train)</span></span>
<span id="cb61-12"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb61-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-13"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb61-13" aria-hidden="true" tabindex="-1"></a><span class="co">tfidf_rf_grid_search.fit(X_train, y_train)</span></span>
<span id="cb61-14"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb61-14" aria-hidden="true" tabindex="-1"></a><span class="co">d2v_rf_grid_search.fit(X_train, y_train)</span></span>
<span id="cb61-15"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb61-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-16"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb61-16" aria-hidden="true" tabindex="-1"></a><span class="co">#Save the models to make it easier to load later</span></span>
<span id="cb61-17"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb61-17" aria-hidden="true" tabindex="-1"></a><span class="co">pickle.dump(bow_lr_grid_search, open('models/logreg_bow.pickle', 'wb'))</span></span>
<span id="cb61-18"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb61-18" aria-hidden="true" tabindex="-1"></a><span class="co">pickle.dump(tfidf_lr_grid_search, open('models/logreg_tfidf.pickle', 'wb'))</span></span>
<span id="cb61-19"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb61-19" aria-hidden="true" tabindex="-1"></a><span class="co">pickle.dump(d2v_lr_grid_search, open('models/logreg_dv.pickle', 'wb'))</span></span>
<span id="cb61-20"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb61-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-21"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb61-21" aria-hidden="true" tabindex="-1"></a><span class="co">pickle.dump(tfidf_svm_grid_search, open('models/svm_tfidf.pickle', 'wb'))</span></span>
<span id="cb61-22"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb61-22" aria-hidden="true" tabindex="-1"></a><span class="co">pickle.dump(d2v_svm_grid_search, open('models/svm_dv.pickle', 'wb'))</span></span>
<span id="cb61-23"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb61-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-24"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb61-24" aria-hidden="true" tabindex="-1"></a><span class="co">pickle.dump(tfidf_knn_grid_search, open('models/knn_tfidf.pickle', 'wb'))</span></span>
<span id="cb61-25"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb61-25" aria-hidden="true" tabindex="-1"></a><span class="co">pickle.dump(d2v_knn_grid_search, open('models/knn_dv.pickle', 'wb'))</span></span>
<span id="cb61-26"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb61-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-27"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb61-27" aria-hidden="true" tabindex="-1"></a><span class="co">pickle.dump(tfidf_rf_grid_search, open('models/rf_tfidf.pickle', 'wb'))</span></span>
<span id="cb61-28"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb61-28" aria-hidden="true" tabindex="-1"></a><span class="co">pickle.dump(d2v_rf_grid_search, open('models/rf_dv.pickle', 'wb'))</span></span>
<span id="cb61-29"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb61-29" aria-hidden="true" tabindex="-1"></a><span class="co">'''</span></span>
<span id="cb61-30"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb61-30" aria-hidden="true" tabindex="-1"></a><span class="co">#loading the models</span></span>
<span id="cb61-31"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb61-31" aria-hidden="true" tabindex="-1"></a>bow_lr_grid_search <span class="op">=</span> pickle.load(<span class="bu">open</span>(<span class="st">'models/logreg_bow.pickle'</span>, <span class="st">'rb'</span>))</span>
<span id="cb61-32"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb61-32" aria-hidden="true" tabindex="-1"></a>tfidf_lr_grid_search <span class="op">=</span> pickle.load(<span class="bu">open</span>(<span class="st">'models/logreg_tfidf.pickle'</span>, <span class="st">'rb'</span>))</span>
<span id="cb61-33"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb61-33" aria-hidden="true" tabindex="-1"></a>d2v_lr_grid_search <span class="op">=</span> pickle.load(<span class="bu">open</span>(<span class="st">'models/logreg_dv.pickle'</span>, <span class="st">'rb'</span>))</span>
<span id="cb61-34"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb61-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-35"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb61-35" aria-hidden="true" tabindex="-1"></a>tfidf_svm_grid_search <span class="op">=</span> pickle.load(<span class="bu">open</span>(<span class="st">'models/svm_tfidf.pickle'</span>, <span class="st">'rb'</span>))</span>
<span id="cb61-36"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb61-36" aria-hidden="true" tabindex="-1"></a>d2v_svm_grid_search <span class="op">=</span> pickle.load(<span class="bu">open</span>(<span class="st">'models/svm_dv.pickle'</span>, <span class="st">'rb'</span>))</span>
<span id="cb61-37"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb61-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-38"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb61-38" aria-hidden="true" tabindex="-1"></a>tfidf_knn_grid_search <span class="op">=</span> pickle.load(<span class="bu">open</span>(<span class="st">'models/knn_tfidf.pickle'</span>, <span class="st">'rb'</span>))</span>
<span id="cb61-39"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb61-39" aria-hidden="true" tabindex="-1"></a>d2v_knn_grid_search <span class="op">=</span> pickle.load(<span class="bu">open</span>(<span class="st">'models/knn_dv.pickle'</span>, <span class="st">'rb'</span>))</span>
<span id="cb61-40"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb61-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-41"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb61-41" aria-hidden="true" tabindex="-1"></a>tfidf_rf_grid_search <span class="op">=</span> pickle.load(<span class="bu">open</span>(<span class="st">'models/rf_tfidf.pickle'</span>, <span class="st">'rb'</span>))</span>
<span id="cb61-42"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb61-42" aria-hidden="true" tabindex="-1"></a>d2v_rf_grid_search <span class="op">=</span> pickle.load(<span class="bu">open</span>(<span class="st">'models/rf_dv.pickle'</span>, <span class="st">'rb'</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>The model fitting actually took 2+ hours no joke.</p>
</section>
<section id="logistic-regression-w-penalty" class="level2">
<h2 class="anchored" data-anchor-id="logistic-regression-w-penalty">Logistic Regression w/ Penalty<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#logistic-regression-w-penalty" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>
<p>Let’s start with Logistic Regression #### Best Model Selection using model.best_estimator_:</p>
<p><strong>Bag of Words:</strong></p>
<div class="cell" data-execution_count="46">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb62-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="co"># print how our model looks after hyper-parameter tuning</span></span>
<span id="cb62-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb62-2" aria-hidden="true" tabindex="-1"></a>lr_bow <span class="op">=</span> bow_lr_grid_search.best_estimator_</span>
<span id="cb62-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb62-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'The best lr_bow model is: </span><span class="sc">{}</span><span class="st">'</span>.<span class="bu">format</span>(bow_lr_grid_search.best_params_))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>The best lr_bow model is: {'classifier__C': 0.5, 'classifier__penalty': 'l2', 'classifier__solver': 'liblinear'}</code></pre>
</div>
</div>
<p><strong>TF-IDF:</strong></p>
<div class="cell" data-execution_count="47">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="co"># print how our model looks after hyper-parameter tuning</span></span>
<span id="cb64-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb64-2" aria-hidden="true" tabindex="-1"></a>lr_tfidf <span class="op">=</span> tfidf_lr_grid_search.best_estimator_</span>
<span id="cb64-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb64-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'The best lr_tfidf model is: </span><span class="sc">{}</span><span class="st">'</span>.<span class="bu">format</span>(tfidf_lr_grid_search.best_params_))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>The best lr_tfidf model is: {'classifier__C': 1.0, 'classifier__penalty': 'l2', 'classifier__solver': 'liblinear'}</code></pre>
</div>
</div>
<p><strong>Doc2Vec:</strong></p>
<div class="cell" data-execution_count="48">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb66-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="co"># print how our model looks after hyper-parameter tuning</span></span>
<span id="cb66-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb66-2" aria-hidden="true" tabindex="-1"></a>lr_d2v <span class="op">=</span> d2v_lr_grid_search.best_estimator_</span>
<span id="cb66-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb66-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'The best lr_d2v model is: </span><span class="sc">{}</span><span class="st">'</span>.<span class="bu">format</span>(d2v_lr_grid_search.best_params_))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>The best lr_d2v model is: {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'liblinear'}</code></pre>
</div>
</div>
<section id="cross-validated-metrics" class="level4">
<h4 class="anchored" data-anchor-id="cross-validated-metrics">Cross Validated Metrics:<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cross-validated-metrics" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h4>
<p><strong>Bag of Words:</strong></p>
<div class="cell" data-execution_count="49">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb68-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="co">#specify which metrics to cross validate</span></span>
<span id="cb68-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb68-2" aria-hidden="true" tabindex="-1"></a>metrics <span class="op">=</span> [<span class="st">'roc_auc'</span>,<span class="st">'accuracy'</span>]</span>
<span id="cb68-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb68-3" aria-hidden="true" tabindex="-1"></a><span class="co">'''</span></span>
<span id="cb68-4"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb68-4" aria-hidden="true" tabindex="-1"></a><span class="co">lr_bow_results = pd.DataFrame(cross_validate(lr_bow, X_train,y_train, scoring=metrics, cv=5))</span></span>
<span id="cb68-5"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb68-5" aria-hidden="true" tabindex="-1"></a><span class="co">lr_bow_results.to_csv('results/lr_bow_results.csv')</span></span>
<span id="cb68-6"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb68-6" aria-hidden="true" tabindex="-1"></a><span class="co">'''</span></span>
<span id="cb68-7"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb68-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-8"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb68-8" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> pd.read_csv(<span class="st">'results/lr_bow_results.csv'</span>).iloc[:,[<span class="dv">3</span>,<span class="dv">4</span>]]</span>
<span id="cb68-9"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb68-9" aria-hidden="true" tabindex="-1"></a>Markdown(tabulate(</span>
<span id="cb68-10"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb68-10" aria-hidden="true" tabindex="-1"></a>  results,headers<span class="op">=</span>results.columns</span>
<span id="cb68-11"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb68-11" aria-hidden="true" tabindex="-1"></a>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="49">
<table class="table table-sm table-striped">
<thead>
<tr class="header">
<th></th>
<th style="text-align: right;">test_roc_auc</th>
<th style="text-align: right;">test_accuracy</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td style="text-align: right;">0.870378</td>
<td style="text-align: right;">0.789179</td>
</tr>
<tr class="even">
<td>1</td>
<td style="text-align: right;">0.877631</td>
<td style="text-align: right;">0.804104</td>
</tr>
<tr class="odd">
<td>2</td>
<td style="text-align: right;">0.869097</td>
<td style="text-align: right;">0.804104</td>
</tr>
<tr class="even">
<td>3</td>
<td style="text-align: right;">0.884983</td>
<td style="text-align: right;">0.811567</td>
</tr>
<tr class="odd">
<td>4</td>
<td style="text-align: right;">0.860562</td>
<td style="text-align: right;">0.783582</td>
</tr>
</tbody>
</table>
</div>
</div>
<p><strong>TF-IDF:</strong></p>
<div class="cell" data-execution_count="50">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb69-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb69-1" aria-hidden="true" tabindex="-1"></a><span class="co">'''</span></span>
<span id="cb69-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb69-2" aria-hidden="true" tabindex="-1"></a><span class="co">lr_tfidf_results = pd.DataFrame(cross_validate(lr_tfidf, X_train,y_train, scoring=metrics, cv=5))</span></span>
<span id="cb69-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb69-3" aria-hidden="true" tabindex="-1"></a><span class="co">lr_tfidf_results.to_csv('results/lr_tfidf_results.csv')</span></span>
<span id="cb69-4"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb69-4" aria-hidden="true" tabindex="-1"></a><span class="co">'''</span></span>
<span id="cb69-5"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb69-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-6"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb69-6" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> pd.read_csv(<span class="st">'results/lr_tfidf_results.csv'</span>).iloc[:,[<span class="dv">3</span>,<span class="dv">4</span>]]</span>
<span id="cb69-7"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb69-7" aria-hidden="true" tabindex="-1"></a>Markdown(tabulate(</span>
<span id="cb69-8"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb69-8" aria-hidden="true" tabindex="-1"></a>  results,headers<span class="op">=</span>results.columns</span>
<span id="cb69-9"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb69-9" aria-hidden="true" tabindex="-1"></a>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="50">
<table class="table table-sm table-striped">
<thead>
<tr class="header">
<th></th>
<th style="text-align: right;">test_roc_auc</th>
<th style="text-align: right;">test_accuracy</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td style="text-align: right;">0.869445</td>
<td style="text-align: right;">0.785448</td>
</tr>
<tr class="even">
<td>1</td>
<td style="text-align: right;">0.885665</td>
<td style="text-align: right;">0.787313</td>
</tr>
<tr class="odd">
<td>2</td>
<td style="text-align: right;">0.879789</td>
<td style="text-align: right;">0.80597</td>
</tr>
<tr class="even">
<td>3</td>
<td style="text-align: right;">0.905979</td>
<td style="text-align: right;">0.813433</td>
</tr>
<tr class="odd">
<td>4</td>
<td style="text-align: right;">0.887907</td>
<td style="text-align: right;">0.802239</td>
</tr>
</tbody>
</table>
</div>
</div>
<p><strong>Doc2Vec:</strong></p>
<div class="cell" data-execution_count="51">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb70-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="co">'''</span></span>
<span id="cb70-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb70-2" aria-hidden="true" tabindex="-1"></a><span class="co">lr_d2v_results = pd.DataFrame(cross_validate(lr_d2v, X_train,y_train, scoring=metrics, cv=5))</span></span>
<span id="cb70-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb70-3" aria-hidden="true" tabindex="-1"></a><span class="co">lr_d2v_results.to_csv('results/lr_d2v_results.csv')</span></span>
<span id="cb70-4"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb70-4" aria-hidden="true" tabindex="-1"></a><span class="co">'''</span></span>
<span id="cb70-5"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb70-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(pd.read_csv(<span class="st">'results/lr_d2v_results.csv'</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>   Unnamed: 0   fit_time  score_time  test_roc_auc  test_accuracy
0           0  20.117487   10.594035      0.815814       0.757463
1           1  18.899075    9.560382      0.804815       0.753731
2           2  19.469190    9.692506      0.819921       0.748134
3           3  19.761972    9.194443      0.829444       0.753731
4           4  18.681815    9.489985      0.815953       0.725746</code></pre>
</div>
</div>
<p>Surprisingly, the TF-IDF embedding performs the best relative to the other models in terms of both accuracy and roc_auc. Let’s move onto testing Predictions.</p>
</section>
<section id="predictions" class="level4">
<h4 class="anchored" data-anchor-id="predictions">Predictions:<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#predictions" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h4>
<div class="cell" data-execution_count="52">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb72-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Let's create predictions from the testing set</span></span>
<span id="cb72-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb72-2" aria-hidden="true" tabindex="-1"></a>y_pred_lg_bow <span class="op">=</span> lr_bow.predict(X_test)</span>
<span id="cb72-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb72-3" aria-hidden="true" tabindex="-1"></a>y_pred_lg_tfidf <span class="op">=</span> lr_tfidf.predict(X_test)</span>
<span id="cb72-4"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb72-4" aria-hidden="true" tabindex="-1"></a>y_pred_lg_dv <span class="op">=</span> lr_d2v.predict(X_test)</span>
<span id="cb72-5"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb72-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-6"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb72-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'The accuracy score for our Bag of Words LogReg model is: </span><span class="sc">{}</span><span class="st">'</span>.<span class="bu">format</span>(accuracy_score(y_test, y_pred_lg_bow)<span class="op">*</span><span class="dv">100</span>))</span>
<span id="cb72-7"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb72-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'The accuracy score for our TF-IDF LogReg model is: </span><span class="sc">{}</span><span class="st">'</span>.<span class="bu">format</span>(accuracy_score(y_test, y_pred_lg_tfidf)<span class="op">*</span><span class="dv">100</span>))</span>
<span id="cb72-8"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb72-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'The accuracy score for our Doc2Vec LogReg model is: </span><span class="sc">{}</span><span class="st">'</span>.<span class="bu">format</span>(accuracy_score(y_test, y_pred_lg_dv)<span class="op">*</span><span class="dv">100</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>The accuracy score for our Bag of Words LogReg model is: 78.25757575757576
The accuracy score for our TF-IDF LogReg model is: 78.4090909090909
The accuracy score for our Doc2Vec LogReg model is: 70.45454545454545</code></pre>
</div>
</div>
<p>Surprisingly, TF-IDF performs the best! I expected Doc2Vec would be best.</p>
</section>
<section id="confusion-matrix" class="level4">
<h4 class="anchored" data-anchor-id="confusion-matrix">Confusion Matrix<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#confusion-matrix" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h4>
<p><strong>Bag of Words:</strong></p>
<div class="cell" data-execution_count="53">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb74-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb74-1" aria-hidden="true" tabindex="-1"></a>sns.heatmap(confusion_matrix(y_test, y_pred_lg_bow), annot<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb74-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb74-2" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Confusion Matrix of Bag of Words LogReg'</span>)</span>
<span id="cb74-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb74-3" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="./Report_files/cell-54-output-1.png" width="538" height="431"></p>
</div>
</div>
<p><strong>TF-IDF:</strong></p>
<div class="cell" data-execution_count="54">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb75-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb75-1" aria-hidden="true" tabindex="-1"></a>sns.heatmap(confusion_matrix(y_test, y_pred_lg_tfidf), annot<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb75-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb75-2" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Confusion Matrix of TF-IDF LogReg'</span>)</span>
<span id="cb75-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb75-3" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="./Report_files/cell-55-output-1.png" width="538" height="431"></p>
</div>
</div>
<p><strong>Doc2Vec:</strong></p>
<div class="cell" data-execution_count="55">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb76"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb76-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb76-1" aria-hidden="true" tabindex="-1"></a>sns.heatmap(confusion_matrix(y_test, y_pred_lg_dv), annot<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb76-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb76-2" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Confusion Matrix of Doc2Vec LogReg'</span>)</span>
<span id="cb76-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb76-3" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="./Report_files/cell-56-output-1.png" width="538" height="431"></p>
</div>
</div>
<p>For logistic regression, we can see that TF-IDF is the best. It achieved the greatest training ROC_AUC and accuracy and greatest Testing accuracy.</p>
</section>
</section>
<section id="support-vector-machines" class="level2">
<h2 class="anchored" data-anchor-id="support-vector-machines">Support Vector Machines<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#support-vector-machines" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>
<p>Since SVC has a hyperparameter C and Gamma, which affects the decision boundary. To reduce computation power, I will not fit/train a Bag of Words embedding since TF-IDF is just a more nuanced Bag of Words embedding.</p>
<p>To do hyperparameter tuning, we will use the GridSearchCV function from sci-kitlearn and by specifiying the hyperparameters grid, we can see which one performs the best.</p>
<section id="best-model-selection-using-model.best_estimator_" class="level4">
<h4 class="anchored" data-anchor-id="best-model-selection-using-model.best_estimator_">Best Model Selection using model.best_estimator_:<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#best-model-selection-using-model.best_estimator_" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h4>
<p><strong>TF-IDF:</strong></p>
<div class="cell" data-execution_count="56">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb77"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb77-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb77-1" aria-hidden="true" tabindex="-1"></a><span class="co"># print how our model looks after hyper-parameter tuning</span></span>
<span id="cb77-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb77-2" aria-hidden="true" tabindex="-1"></a>svm_tfidf <span class="op">=</span> tfidf_svm_grid_search.best_estimator_</span>
<span id="cb77-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb77-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'The best knn_tfidf model is: </span><span class="sc">{}</span><span class="st">'</span>.<span class="bu">format</span>(tfidf_svm_grid_search.best_params_))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>The best knn_tfidf model is: {'classifier__C': 10, 'classifier__kernel': 'rbf'}</code></pre>
</div>
</div>
<p><strong>Doc2Vec:</strong></p>
<div class="cell" data-execution_count="57">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb79"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb79-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="co"># print how our model looks after hyper-parameter tuning</span></span>
<span id="cb79-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb79-2" aria-hidden="true" tabindex="-1"></a>svm_d2v <span class="op">=</span> d2v_svm_grid_search.best_estimator_</span>
<span id="cb79-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb79-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'The best knn_d2v model is: </span><span class="sc">{}</span><span class="st">'</span>.<span class="bu">format</span>(d2v_svm_grid_search.best_params_))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>The best knn_d2v model is: {'classifier__C': 1, 'classifier__kernel': 'rbf'}</code></pre>
</div>
</div>
</section>
<section id="cross-validated-metrics-1" class="level4">
<h4 class="anchored" data-anchor-id="cross-validated-metrics-1">Cross Validated Metrics:<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cross-validated-metrics-1" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h4>
<p><strong>TF-IDF:</strong></p>
<div class="cell" data-execution_count="58">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb81"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb81-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb81-1" aria-hidden="true" tabindex="-1"></a><span class="co">'''</span></span>
<span id="cb81-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb81-2" aria-hidden="true" tabindex="-1"></a><span class="co">svm_tfidf_results = pd.DataFrame(cross_validate(svm_tfidf, X_train,y_train, scoring=metrics, cv=5))</span></span>
<span id="cb81-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb81-3" aria-hidden="true" tabindex="-1"></a><span class="co">svm_tfidf_results.to_csv('results/svm_tfidf_results.csv')</span></span>
<span id="cb81-4"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb81-4" aria-hidden="true" tabindex="-1"></a><span class="co">'''</span></span>
<span id="cb81-5"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb81-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-6"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb81-6" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> pd.read_csv(<span class="st">'results/svm_tfidf_results.csv'</span>).iloc[:,[<span class="dv">3</span>,<span class="dv">4</span>]]</span>
<span id="cb81-7"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb81-7" aria-hidden="true" tabindex="-1"></a>Markdown(tabulate(</span>
<span id="cb81-8"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb81-8" aria-hidden="true" tabindex="-1"></a>  results,headers<span class="op">=</span>results.columns</span>
<span id="cb81-9"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb81-9" aria-hidden="true" tabindex="-1"></a>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="58">
<table class="table table-sm table-striped">
<thead>
<tr class="header">
<th></th>
<th style="text-align: right;">test_roc_auc</th>
<th style="text-align: right;">test_accuracy</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td style="text-align: right;">0.875446</td>
<td style="text-align: right;">0.781716</td>
</tr>
<tr class="even">
<td>1</td>
<td style="text-align: right;">0.888241</td>
<td style="text-align: right;">0.796642</td>
</tr>
<tr class="odd">
<td>2</td>
<td style="text-align: right;">0.881808</td>
<td style="text-align: right;">0.817164</td>
</tr>
<tr class="even">
<td>3</td>
<td style="text-align: right;">0.904336</td>
<td style="text-align: right;">0.813433</td>
</tr>
<tr class="odd">
<td>4</td>
<td style="text-align: right;">0.884802</td>
<td style="text-align: right;">0.809701</td>
</tr>
</tbody>
</table>
</div>
</div>
<p><strong>Doc2Vec:</strong></p>
<div class="cell" data-execution_count="59">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb82"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb82-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb82-1" aria-hidden="true" tabindex="-1"></a><span class="co">'''</span></span>
<span id="cb82-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb82-2" aria-hidden="true" tabindex="-1"></a><span class="co">svm_d2v_results = pd.DataFrame(cross_validate(svm_d2v, X_train,y_train, scoring=metrics, cv=5))</span></span>
<span id="cb82-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb82-3" aria-hidden="true" tabindex="-1"></a><span class="co">svm_d2v_results.to_csv('results/d2v_tfidf_results.csv')</span></span>
<span id="cb82-4"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb82-4" aria-hidden="true" tabindex="-1"></a><span class="co">'''</span></span>
<span id="cb82-5"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb82-5" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> pd.read_csv(<span class="st">'results/d2v_tfidf_results.csv'</span>).iloc[:,[<span class="dv">3</span>,<span class="dv">4</span>]]</span>
<span id="cb82-6"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb82-6" aria-hidden="true" tabindex="-1"></a>Markdown(tabulate(</span>
<span id="cb82-7"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb82-7" aria-hidden="true" tabindex="-1"></a>  results,headers<span class="op">=</span>results.columns</span>
<span id="cb82-8"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb82-8" aria-hidden="true" tabindex="-1"></a>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="59">
<table class="table table-sm table-striped">
<thead>
<tr class="header">
<th></th>
<th style="text-align: right;">test_roc_auc</th>
<th style="text-align: right;">test_accuracy</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td style="text-align: right;">0.826687</td>
<td style="text-align: right;">0.75</td>
</tr>
<tr class="even">
<td>1</td>
<td style="text-align: right;">0.82446</td>
<td style="text-align: right;">0.75</td>
</tr>
<tr class="odd">
<td>2</td>
<td style="text-align: right;">0.828818</td>
<td style="text-align: right;">0.75</td>
</tr>
<tr class="even">
<td>3</td>
<td style="text-align: right;">0.826576</td>
<td style="text-align: right;">0.772388</td>
</tr>
<tr class="odd">
<td>4</td>
<td style="text-align: right;">0.813461</td>
<td style="text-align: right;">0.748134</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>Again, surprisingly TF-IDF performs so well on the training set. But it might be slightly overfitting.</p>
</section>
<section id="predictions-1" class="level4">
<h4 class="anchored" data-anchor-id="predictions-1">Predictions:<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#predictions-1" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h4>
<div class="cell" data-execution_count="60">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb83"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb83-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb83-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Let's create predictions from the testing set</span></span>
<span id="cb83-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb83-2" aria-hidden="true" tabindex="-1"></a>y_pred_svm_tfidf <span class="op">=</span> svm_tfidf.predict(X_test)</span>
<span id="cb83-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb83-3" aria-hidden="true" tabindex="-1"></a>y_pred_svm_dv <span class="op">=</span> svm_d2v.predict(X_test)</span>
<span id="cb83-4"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb83-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-5"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb83-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'The accuracy score for our TF-IDF SVM model is: </span><span class="sc">{}</span><span class="st">'</span>.<span class="bu">format</span>(accuracy_score(y_test, y_pred_svm_tfidf)<span class="op">*</span><span class="dv">100</span>))</span>
<span id="cb83-6"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb83-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'The accuracy score for our Doc2Vec SVM model is: </span><span class="sc">{}</span><span class="st">'</span>.<span class="bu">format</span>(accuracy_score(y_test, y_pred_svm_dv)<span class="op">*</span><span class="dv">100</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>The accuracy score for our TF-IDF SVM model is: 79.24242424242425
The accuracy score for our Doc2Vec SVM model is: 72.34848484848484</code></pre>
</div>
</div>
<p>Again, TF-IDF is outperforming Doc2Vec.</p>
</section>
<section id="confusion-matrix-1" class="level4">
<h4 class="anchored" data-anchor-id="confusion-matrix-1">Confusion Matrix<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#confusion-matrix-1" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h4>
<p><strong>TF-IDF:</strong></p>
<div class="cell" data-execution_count="61">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb85"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb85-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb85-1" aria-hidden="true" tabindex="-1"></a>sns.heatmap(confusion_matrix(y_test, y_pred_svm_tfidf), annot<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb85-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb85-2" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Confusion Matrix of TF-IDF SVM'</span>)</span>
<span id="cb85-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb85-3" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="./Report_files/cell-62-output-1.png" width="538" height="431"></p>
</div>
</div>
<p><strong>Doc2Vec:</strong></p>
<div class="cell" data-execution_count="62">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb86"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb86-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb86-1" aria-hidden="true" tabindex="-1"></a>sns.heatmap(confusion_matrix(y_test, y_pred_svm_dv), annot<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb86-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb86-2" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Confusion Matrix of Doc2Vec SVM'</span>)</span>
<span id="cb86-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb86-3" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="./Report_files/cell-63-output-1.png" width="538" height="431"></p>
</div>
</div>
</section>
</section>
<section id="k-nearest-neighbors" class="level2">
<h2 class="anchored" data-anchor-id="k-nearest-neighbors">K-Nearest neighbors<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#k-nearest-neighbors" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>
<p>K-nearest neighbors uses hyperparameter k to determine how many clusters/neighbors to use.</p>
<section id="best-model-selection-using-model.best_estimator_-1" class="level4">
<h4 class="anchored" data-anchor-id="best-model-selection-using-model.best_estimator_-1">Best Model Selection using model.best_estimator_:<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#best-model-selection-using-model.best_estimator_-1" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h4>
<p><strong>TF-IDF:</strong></p>
<div class="cell" data-execution_count="63">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb87"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb87-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb87-1" aria-hidden="true" tabindex="-1"></a><span class="co"># print how our model looks after hyper-parameter tuning</span></span>
<span id="cb87-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb87-2" aria-hidden="true" tabindex="-1"></a>knn_tfidf <span class="op">=</span> tfidf_knn_grid_search.best_estimator_</span>
<span id="cb87-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb87-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'The best knn_tfidf model is: </span><span class="sc">{}</span><span class="st">'</span>.<span class="bu">format</span>(tfidf_knn_grid_search.best_params_))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>The best knn_tfidf model is: {'classifier__metric': 'euclidean', 'classifier__n_neighbors': 6, 'classifier__weights': 'distance'}</code></pre>
</div>
</div>
<p><strong>Doc2Vec:</strong></p>
<div class="cell" data-execution_count="64">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb89"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb89-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb89-1" aria-hidden="true" tabindex="-1"></a><span class="co"># print how our model looks after hyper-parameter tuning</span></span>
<span id="cb89-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb89-2" aria-hidden="true" tabindex="-1"></a>knn_d2v <span class="op">=</span> d2v_knn_grid_search.best_estimator_</span>
<span id="cb89-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb89-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'The best knn_d2v model is: </span><span class="sc">{}</span><span class="st">'</span>.<span class="bu">format</span>(d2v_knn_grid_search.best_params_))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>The best knn_d2v model is: {'classifier__metric': 'euclidean', 'classifier__n_neighbors': 6, 'classifier__weights': 'uniform'}</code></pre>
</div>
</div>
</section>
<section id="cross-validated-metrics-2" class="level4">
<h4 class="anchored" data-anchor-id="cross-validated-metrics-2">Cross Validated Metrics:<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cross-validated-metrics-2" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h4>
<p><strong>TF-IDF:</strong></p>
<div class="cell" data-execution_count="65">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb91"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb91-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="co">'''</span></span>
<span id="cb91-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb91-2" aria-hidden="true" tabindex="-1"></a><span class="co">knn_tfidf_results = pd.DataFrame(cross_validate(knn_tfidf, X_train,y_train, scoring=metrics, cv=5))</span></span>
<span id="cb91-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb91-3" aria-hidden="true" tabindex="-1"></a><span class="co">knn_tfidf_results.to_csv('results/knn_tfidf_results.csv')</span></span>
<span id="cb91-4"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb91-4" aria-hidden="true" tabindex="-1"></a><span class="co">'''</span></span>
<span id="cb91-5"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb91-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb91-6"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb91-6" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> pd.read_csv(<span class="st">'results/knn_tfidf_results.csv'</span>).iloc[:,[<span class="dv">3</span>,<span class="dv">4</span>]]</span>
<span id="cb91-7"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb91-7" aria-hidden="true" tabindex="-1"></a>Markdown(tabulate(</span>
<span id="cb91-8"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb91-8" aria-hidden="true" tabindex="-1"></a>  results,headers<span class="op">=</span>results.columns</span>
<span id="cb91-9"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb91-9" aria-hidden="true" tabindex="-1"></a>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="65">
<table class="table table-sm table-striped">
<thead>
<tr class="header">
<th></th>
<th style="text-align: right;">test_roc_auc</th>
<th style="text-align: right;">test_accuracy</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td style="text-align: right;">0.668976</td>
<td style="text-align: right;">0.621269</td>
</tr>
<tr class="even">
<td>1</td>
<td style="text-align: right;">0.701019</td>
<td style="text-align: right;">0.63806</td>
</tr>
<tr class="odd">
<td>2</td>
<td style="text-align: right;">0.683936</td>
<td style="text-align: right;">0.636194</td>
</tr>
<tr class="even">
<td>3</td>
<td style="text-align: right;">0.712673</td>
<td style="text-align: right;">0.643657</td>
</tr>
<tr class="odd">
<td>4</td>
<td style="text-align: right;">0.724744</td>
<td style="text-align: right;">0.649254</td>
</tr>
</tbody>
</table>
</div>
</div>
<p><strong>Doc2Vec:</strong></p>
<div class="cell" data-execution_count="66">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb92"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb92-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb92-1" aria-hidden="true" tabindex="-1"></a><span class="co">'''</span></span>
<span id="cb92-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb92-2" aria-hidden="true" tabindex="-1"></a><span class="co">knn_d2v_results = pd.DataFrame(cross_validate(knn_d2v, X_train,y_train, scoring=metrics, cv=5))</span></span>
<span id="cb92-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb92-3" aria-hidden="true" tabindex="-1"></a><span class="co">knn_d2v_results.to_csv('results/knn_d2v_results.csv')</span></span>
<span id="cb92-4"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb92-4" aria-hidden="true" tabindex="-1"></a><span class="co">'''</span></span>
<span id="cb92-5"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb92-5" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> pd.read_csv(<span class="st">'results/knn_d2v_results.csv'</span>).iloc[:,[<span class="dv">3</span>,<span class="dv">4</span>]]</span>
<span id="cb92-6"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb92-6" aria-hidden="true" tabindex="-1"></a>Markdown(tabulate(</span>
<span id="cb92-7"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb92-7" aria-hidden="true" tabindex="-1"></a>  results,headers<span class="op">=</span>results.columns</span>
<span id="cb92-8"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb92-8" aria-hidden="true" tabindex="-1"></a>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="66">
<table class="table table-sm table-striped">
<thead>
<tr class="header">
<th></th>
<th style="text-align: right;">test_roc_auc</th>
<th style="text-align: right;">test_accuracy</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td style="text-align: right;">0.654148</td>
<td style="text-align: right;">0.591418</td>
</tr>
<tr class="even">
<td>1</td>
<td style="text-align: right;">0.670347</td>
<td style="text-align: right;">0.589552</td>
</tr>
<tr class="odd">
<td>2</td>
<td style="text-align: right;">0.625383</td>
<td style="text-align: right;">0.591418</td>
</tr>
<tr class="even">
<td>3</td>
<td style="text-align: right;">0.647813</td>
<td style="text-align: right;">0.58209</td>
</tr>
<tr class="odd">
<td>4</td>
<td style="text-align: right;">0.635902</td>
<td style="text-align: right;">0.572761</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>Oh, KNN performs quite terribly on the data compared to the first two models we tried. From this, this is probably because our word embedding makes the data turn to a large number of features (great number of columns). And because of this, KNN struggles!</p>
</section>
<section id="predictions-2" class="level4">
<h4 class="anchored" data-anchor-id="predictions-2">Predictions:<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#predictions-2" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h4>
<div class="cell" data-execution_count="67">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb93"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb93-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb93-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Let's create predictions from the testing set</span></span>
<span id="cb93-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb93-2" aria-hidden="true" tabindex="-1"></a>y_pred_knn_tfidf <span class="op">=</span> knn_tfidf.predict(X_test)</span>
<span id="cb93-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb93-3" aria-hidden="true" tabindex="-1"></a>y_pred_knn_dv <span class="op">=</span> knn_d2v.predict(X_test)</span>
<span id="cb93-4"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb93-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-5"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb93-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'The accuracy score for our TF-IDF KNN model is: </span><span class="sc">{}</span><span class="st">'</span>.<span class="bu">format</span>(accuracy_score(y_test, y_pred_knn_tfidf)<span class="op">*</span><span class="dv">100</span>))</span>
<span id="cb93-6"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb93-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'The accuracy score for our Doc2Vec KNN model is: </span><span class="sc">{}</span><span class="st">'</span>.<span class="bu">format</span>(accuracy_score(y_test, y_pred_knn_dv)<span class="op">*</span><span class="dv">100</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>The accuracy score for our TF-IDF KNN model is: 62.5
The accuracy score for our Doc2Vec KNN model is: 62.272727272727266</code></pre>
</div>
</div>
<p>Surprisingly, TF-IDF performs the best.</p>
</section>
<section id="confusion-matrix-2" class="level4">
<h4 class="anchored" data-anchor-id="confusion-matrix-2">Confusion Matrix<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#confusion-matrix-2" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h4>
<p><strong>TF-IDF:</strong></p>
<div class="cell" data-execution_count="68">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb95"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb95-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb95-1" aria-hidden="true" tabindex="-1"></a>sns.heatmap(confusion_matrix(y_test, y_pred_knn_tfidf), annot<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb95-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb95-2" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Confusion Matrix of TF-IDF KNN'</span>)</span>
<span id="cb95-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb95-3" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="./Report_files/cell-69-output-1.png" width="538" height="431"></p>
</div>
</div>
<p><strong>Doc2Vec:</strong></p>
<div class="cell" data-execution_count="69">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb96"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb96-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb96-1" aria-hidden="true" tabindex="-1"></a>sns.heatmap(confusion_matrix(y_test, y_pred_knn_dv), annot<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb96-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb96-2" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Confusion Matrix of Doc2Vec KNN'</span>)</span>
<span id="cb96-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb96-3" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="./Report_files/cell-70-output-1.png" width="538" height="431"></p>
</div>
</div>
</section>
</section>
<section id="random-forest-classifier" class="level2">
<h2 class="anchored" data-anchor-id="random-forest-classifier">Random Forest Classifier<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#random-forest-classifier" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>
<section id="best-model-selection-using-model.best_estimator_-2" class="level4">
<h4 class="anchored" data-anchor-id="best-model-selection-using-model.best_estimator_-2">Best Model Selection using model.best_estimator_:<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#best-model-selection-using-model.best_estimator_-2" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h4>
<p><strong>TF-IDF:</strong></p>
<div class="cell" data-execution_count="70">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb97"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb97-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb97-1" aria-hidden="true" tabindex="-1"></a><span class="co"># print how our model looks after hyper-parameter tuning</span></span>
<span id="cb97-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb97-2" aria-hidden="true" tabindex="-1"></a>rf_tfidf <span class="op">=</span> tfidf_rf_grid_search.best_estimator_</span>
<span id="cb97-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb97-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'The best knn_tfidf model is: </span><span class="sc">{}</span><span class="st">'</span>.<span class="bu">format</span>(tfidf_rf_grid_search.best_params_))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>The best knn_tfidf model is: {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 6}</code></pre>
</div>
</div>
<p><strong>Doc2Vec:</strong></p>
<div class="cell" data-execution_count="71">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb99"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb99-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb99-1" aria-hidden="true" tabindex="-1"></a><span class="co"># print how our model looks after hyper-parameter tuning</span></span>
<span id="cb99-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb99-2" aria-hidden="true" tabindex="-1"></a>rf_d2v <span class="op">=</span> d2v_rf_grid_search.best_estimator_</span>
<span id="cb99-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb99-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'The best knn_d2v model is: </span><span class="sc">{}</span><span class="st">'</span>.<span class="bu">format</span>(d2v_rf_grid_search.best_params_))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>The best knn_d2v model is: {'classifier__max_depth': 6, 'classifier__min_samples_leaf': 3, 'classifier__min_samples_split': 3}</code></pre>
</div>
</div>
</section>
<section id="cross-validated-metrics-3" class="level4">
<h4 class="anchored" data-anchor-id="cross-validated-metrics-3">Cross Validated Metrics:<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cross-validated-metrics-3" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h4>
<p><strong>TF-IDF:</strong></p>
<div class="cell" data-execution_count="72">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb101"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb101-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb101-1" aria-hidden="true" tabindex="-1"></a><span class="co">'''</span></span>
<span id="cb101-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb101-2" aria-hidden="true" tabindex="-1"></a><span class="co">rf_tfidf_results = pd.DataFrame(cross_validate(rf_tfidf, X_train,y_train, scoring=metrics, cv=5))</span></span>
<span id="cb101-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb101-3" aria-hidden="true" tabindex="-1"></a><span class="co">rf_tfidf_results.to_csv('results/rf_tfidf_results.csv')</span></span>
<span id="cb101-4"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb101-4" aria-hidden="true" tabindex="-1"></a><span class="co">'''</span></span>
<span id="cb101-5"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb101-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb101-6"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb101-6" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> pd.read_csv(<span class="st">'results/rf_tfidf_results.csv'</span>).iloc[:,[<span class="dv">3</span>,<span class="dv">4</span>]]</span>
<span id="cb101-7"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb101-7" aria-hidden="true" tabindex="-1"></a>Markdown(tabulate(</span>
<span id="cb101-8"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb101-8" aria-hidden="true" tabindex="-1"></a>  results,headers<span class="op">=</span>results.columns</span>
<span id="cb101-9"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb101-9" aria-hidden="true" tabindex="-1"></a>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="72">
<table class="table table-sm table-striped">
<thead>
<tr class="header">
<th></th>
<th style="text-align: right;">test_roc_auc</th>
<th style="text-align: right;">test_accuracy</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td style="text-align: right;">0.840095</td>
<td style="text-align: right;">0.746269</td>
</tr>
<tr class="even">
<td>1</td>
<td style="text-align: right;">0.85218</td>
<td style="text-align: right;">0.757463</td>
</tr>
<tr class="odd">
<td>2</td>
<td style="text-align: right;">0.852125</td>
<td style="text-align: right;">0.772388</td>
</tr>
<tr class="even">
<td>3</td>
<td style="text-align: right;">0.853232</td>
<td style="text-align: right;">0.774254</td>
</tr>
<tr class="odd">
<td>4</td>
<td style="text-align: right;">0.846291</td>
<td style="text-align: right;">0.764925</td>
</tr>
</tbody>
</table>
</div>
</div>
<p><strong>Doc2Vec:</strong></p>
<div class="cell" data-execution_count="73">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb102"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb102-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb102-1" aria-hidden="true" tabindex="-1"></a><span class="co">'''</span></span>
<span id="cb102-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb102-2" aria-hidden="true" tabindex="-1"></a><span class="co">rf_d2v_results = pd.DataFrame(cross_validate(rf_d2v, X_train,y_train, scoring=metrics, cv=5))</span></span>
<span id="cb102-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb102-3" aria-hidden="true" tabindex="-1"></a><span class="co">rf_d2v_results.to_csv('results/rf_d2v_results.csv')</span></span>
<span id="cb102-4"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb102-4" aria-hidden="true" tabindex="-1"></a><span class="co">'''</span></span>
<span id="cb102-5"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb102-5" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> pd.read_csv(<span class="st">'results/rf_d2v_results.csv'</span>).iloc[:,[<span class="dv">3</span>,<span class="dv">4</span>]]</span>
<span id="cb102-6"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb102-6" aria-hidden="true" tabindex="-1"></a>Markdown(tabulate(</span>
<span id="cb102-7"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb102-7" aria-hidden="true" tabindex="-1"></a>  results,headers<span class="op">=</span>results.columns</span>
<span id="cb102-8"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb102-8" aria-hidden="true" tabindex="-1"></a>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="73">
<table class="table table-sm table-striped">
<thead>
<tr class="header">
<th></th>
<th style="text-align: right;">test_roc_auc</th>
<th style="text-align: right;">test_accuracy</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td style="text-align: right;">0.791727</td>
<td style="text-align: right;">0.710821</td>
</tr>
<tr class="even">
<td>1</td>
<td style="text-align: right;">0.774644</td>
<td style="text-align: right;">0.701493</td>
</tr>
<tr class="odd">
<td>2</td>
<td style="text-align: right;">0.777108</td>
<td style="text-align: right;">0.701493</td>
</tr>
<tr class="even">
<td>3</td>
<td style="text-align: right;">0.786144</td>
<td style="text-align: right;">0.718284</td>
</tr>
<tr class="odd">
<td>4</td>
<td style="text-align: right;">0.77818</td>
<td style="text-align: right;">0.720149</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>Random Forest actually did slightly worse than Support Vector Machines. Still, TF-IDF performs better than the Doc2Vec model.</p>
</section>
<section id="predictions-3" class="level4">
<h4 class="anchored" data-anchor-id="predictions-3">Predictions:<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#predictions-3" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h4>
<div class="cell" data-execution_count="74">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb103"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb103-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb103-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Let's create predictions from the testing set</span></span>
<span id="cb103-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb103-2" aria-hidden="true" tabindex="-1"></a>y_pred_rf_tfidf <span class="op">=</span> rf_tfidf.predict(X_test)</span>
<span id="cb103-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb103-3" aria-hidden="true" tabindex="-1"></a>y_pred_rf_dv <span class="op">=</span> rf_d2v.predict(X_test)</span>
<span id="cb103-4"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb103-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-5"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb103-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'The accuracy score for our TF-IDF RF model is: </span><span class="sc">{}</span><span class="st">'</span>.<span class="bu">format</span>(accuracy_score(y_test, y_pred_rf_tfidf)<span class="op">*</span><span class="dv">100</span>))</span>
<span id="cb103-6"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb103-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'The accuracy score for our Doc2Vec RF model is: </span><span class="sc">{}</span><span class="st">'</span>.<span class="bu">format</span>(accuracy_score(y_test, y_pred_rf_dv)<span class="op">*</span><span class="dv">100</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>The accuracy score for our TF-IDF RF model is: 75.53030303030303
The accuracy score for our Doc2Vec RF model is: 67.95454545454545</code></pre>
</div>
</div>
<p>Again, TF-IDF performed the best. And Random Forest actually did worse than Support Vector Machines.</p>
</section>
<section id="confusion-matrix-3" class="level4">
<h4 class="anchored" data-anchor-id="confusion-matrix-3">Confusion Matrix<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#confusion-matrix-3" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h4>
<p><strong>TF-IDF:</strong></p>
<div class="cell" data-execution_count="75">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb105"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb105-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb105-1" aria-hidden="true" tabindex="-1"></a>sns.heatmap(confusion_matrix(y_test, y_pred_rf_tfidf), annot<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb105-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb105-2" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Confusion Matrix of TF-IDF RF'</span>)</span>
<span id="cb105-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb105-3" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="./Report_files/cell-76-output-1.png" width="538" height="431"></p>
</div>
</div>
<p><strong>Doc2Vec:</strong></p>
<div class="cell" data-execution_count="76">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb106"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb106-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb106-1" aria-hidden="true" tabindex="-1"></a>sns.heatmap(confusion_matrix(y_test, y_pred_rf_dv), annot<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb106-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb106-2" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Confusion Matrix of Doc2Vec RF'</span>)</span>
<span id="cb106-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb106-3" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="./Report_files/cell-77-output-1.png" width="538" height="431"></p>
</div>
</div>
</section>
</section>
<section id="the-best-model" class="level2">
<h2 class="anchored" data-anchor-id="the-best-model">The Best Model<a class="anchorjs-link " aria-label="Anchor" data-anchorjs-icon="" href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#the-best-model" style="font: 1em / 1 anchorjs-icons; padding-left: 0.375em;"></a></h2>
<p>After seeing the model results, we can see that the best model is the TF-IDF SVM model and followed by the TF-IDF Random Forest Model. I honestly expected the Doc2Vec model to perform better as it keeps contextual and semantic information about the text better than the TF-IDF embedding but this shows that I probably need to tune the hyperparameter of the Doc2Vec model better, and I need to clean my texts better.</p>
<div class="cell" data-execution_count="77">
<details>
<summary>code</summary>
<div class="sourceCode cell-code" id="cb107"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb107-1"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb107-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'The two best models are: </span><span class="ch">\n\n</span><span class="st">Support Vector Machines TF-IDF with: </span><span class="ch">\n</span><span class="sc">{}</span><span class="ch">\n\n</span><span class="st">Random Forest TF-IDF with: </span><span class="ch">\n</span><span class="sc">{}</span><span class="st">'</span>.<span class="bu">format</span>(tfidf_rf_grid_search.best_params_,tfidf_svm_grid_search.best_params_))</span>
<span id="cb107-2"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb107-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-3"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb107-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'</span><span class="ch">\n</span><span class="st">The SVM model reached a testing accuracy of </span><span class="sc">{}</span><span class="ch">\n</span><span class="st">The RF model reached a testing accuracy of </span><span class="sc">{}</span><span class="st">'</span>.<span class="bu">format</span>(<span class="bu">round</span>(accuracy_score(y_test, y_pred_svm_tfidf)<span class="op">*</span><span class="dv">100</span>,<span class="dv">2</span>),<span class="bu">round</span>(accuracy_score(y_test, y_pred_rf_tfidf)<span class="op">*</span><span class="dv">100</span>,<span class="dv">2</span>)))</span>
<span id="cb107-4"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb107-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-5"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb107-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'</span><span class="ch">\n</span><span class="st">The SVM model reached a training ROC_AUC score of </span><span class="sc">{}</span><span class="ch">\n</span><span class="st">The RF model reached a training ROC_AUC score of </span><span class="sc">{}</span><span class="st">'</span>.<span class="bu">format</span>(<span class="bu">round</span>(<span class="dv">100</span><span class="op">*</span>np.mean(pd.read_csv(<span class="st">'results/svm_tfidf_results.csv'</span>).loc[:,<span class="st">'test_roc_auc'</span>]),<span class="dv">2</span>),<span class="bu">round</span>(<span class="dv">100</span><span class="op">*</span>np.mean(pd.read_csv(<span class="st">'results/rf_tfidf_results.csv'</span>).loc[:,<span class="st">'test_roc_auc'</span>]),<span class="dv">2</span>)))</span>
<span id="cb107-6"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb107-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-7"><a href="file:///C:/Users/neals/Documents/GitHub/sent_amazon/Final-Project-Report.html#cb107-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'</span><span class="ch">\n</span><span class="st">The SVM model reached a training accuracy score of </span><span class="sc">{}</span><span class="ch">\n</span><span class="st">The RF model reached a training accuracy score of </span><span class="sc">{}</span><span class="st">'</span>.<span class="bu">format</span>(<span class="bu">round</span>(<span class="dv">100</span><span class="op">*</span>np.mean(pd.read_csv(<span class="st">'results/svm_tfidf_results.csv'</span>).loc[:,<span class="st">'test_accuracy'</span>]),<span class="dv">2</span>),<span class="bu">round</span>(<span class="dv">100</span><span class="op">*</span>np.mean(pd.read_csv(<span class="st">'results/rf_tfidf_results.csv'</span>).loc[:,<span class="st">'test_accuracy'</span>]),<span class="dv">2</span>)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>The two best models are: 

Support Vector Machines TF-IDF with: 
{'classifier__max_depth': 6, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 6}

Random Forest TF-IDF with: 
{'classifier__C': 10, 'classifier__kernel': 'rbf'}

The SVM model reached a testing accuracy of 79.24
The RF model reached a testing accuracy of 75.53

The SVM model reached a training ROC_AUC score of 88.69
The RF model reached a training ROC_AUC score of 84.88

The SVM model reached a training accuracy score of 80.37
The RF model reached a training accuracy score of 76.31</code></pre>
</div>
</div>
<p>The SVM TF-IDF model reached a training ROC_AUC score of 88.69%. That’s really high!</p>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>I hope from this project could serve as an introductory project to NLP projects.</p>
<p>There are lots and lots of other NLP techniques to explore like: 1. Other word embedding techniques 2. Custom stopwords 3. How to handle mispellings 4. Name entitity recognition 5. Part of speech tagging and many more!</p>
<p>I think I could have improved my models by handling mispellings and really removing more useless words that went through my stopwords list. Also, I could try changing the list of stopwords to use to preprocess my data as some stopwords list have more stopwords than others, like the ‘snowball’ stopwords list.</p>
<p>Another thing that I could have trained is to tune the hyperparameters that Doc2Vec uses, which currently I have set min_count = 200. By changing that, increasing the number of epochs (iterations to go through the dataset to train), and increasing the number of datapoints fed into the model, I could have probably produced a better and more accurate representation of the reviews in the document. However, this would add to my computational time and requires vastly more computational power which I frankly don’t have.</p>
<p>Nonetheless, this was fantastic opportunity to learn NLP basics and modelling in Python. Before this, I never knew about word embedding or different pipelines. If I continued with trying to model in Python, I would want to explore different ways to hyperparameter tuning like RandomSearchCV or Bayesian Optimization, which I did before.</p>
<p>Furthermore, I also heard that there are a lot of Neural Networks that works well with sequential data like RNN, LSTM, Gated RNN, Transformer models. Though it requires lots of computational power, it might be worth it to explore as it might have a better ability to use contextual information in predicting new texts.</p>
<p>Other than that, that’s all! Thank you for reading!</p>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>